{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d537d466-c6a3-400b-9f33-1f17ffc5f8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyQTorch logger successfully setup with log level 20\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "import pytest\n",
    "import torch\n",
    "\n",
    "import pyqtorch as pyq\n",
    "from pyqtorch import DiffMode, expectation\n",
    "from pyqtorch.analog import Observable\n",
    "from pyqtorch.circuit import QuantumCircuit\n",
    "from pyqtorch.matrices import COMPLEX_TO_REAL_DTYPES\n",
    "from pyqtorch.parametric import Parametric\n",
    "from pyqtorch.utils import GPSR_ACCEPTANCE, PSR_ACCEPTANCE, GRADCHECK_sampling_ATOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45b3249-47bb-4d60-97c2-2e000e0fc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyqtorch.analog import Add, Scale\n",
    "from pyqtorch.apply import apply_operator\n",
    "from pyqtorch.circuit import Sequence\n",
    "from pyqtorch.parametric import (\n",
    "    OPS_PARAM_1Q,\n",
    "    OPS_PARAM_2Q,\n",
    "    Parametric,\n",
    ")\n",
    "from pyqtorch.primitive import (\n",
    "    OPS_1Q,\n",
    "    OPS_2Q,\n",
    "    OPS_3Q,\n",
    "    OPS_PAULI,\n",
    "    OPS_PAULI_with_generator,\n",
    "    Primitive,\n",
    "    Toffoli,\n",
    ")\n",
    "\n",
    "def random_pauli_hamiltonian(\n",
    "    n_qubits: int,\n",
    "    k_1q: int = 5,\n",
    "    k_2q: int = 10,\n",
    "    make_param: bool = False,\n",
    "    exclude_N: bool = False,\n",
    ") -> tuple[Sequence, list]:\n",
    "    \"\"\"Creates a random Pauli Hamiltonian as a sum of k_1q + k_2q terms.\"\"\"\n",
    "    OPS_PAULI_choice = list(OPS_PAULI)\n",
    "    if exclude_N:\n",
    "        OPS_PAULI_choice = list(OPS_PAULI_with_generator)\n",
    "    one_q_terms: list = random.choices(OPS_PAULI_choice, k=k_1q)\n",
    "    two_q_terms: list = [random.choices(OPS_PAULI_choice, k=2) for _ in range(k_2q)]\n",
    "    terms: list = []\n",
    "    for term in one_q_terms:\n",
    "        supp = random.sample(range(n_qubits), 1)\n",
    "        terms.append(term(supp))\n",
    "    for term in two_q_terms:\n",
    "        supp = random.sample(range(n_qubits), 2)\n",
    "        terms.append(Sequence([term[0](supp[0]), term[1](supp[1])]))\n",
    "    param_list = []\n",
    "    for i, t in enumerate(terms):\n",
    "        if random.random() > 0.5:\n",
    "            if make_param:\n",
    "                terms[i] = Scale(t, f\"p_{i}\")\n",
    "                param_list.append(f\"p_{i}\")\n",
    "            else:\n",
    "                terms[i] = Scale(t, torch.rand(1))\n",
    "    return Add(terms), param_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a1ae227-e6ab-4296-96ef-1be3ed23b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit_gpsr(n_qubits: int) -> QuantumCircuit:\n",
    "    \"\"\"Helper function to make an example circuit using multi gap GPSR.\"\"\"\n",
    "\n",
    "    ops = [\n",
    "        pyq.Y(1),\n",
    "        pyq.RX(0, \"theta_0\"),\n",
    "        pyq.PHASE(0, \"theta_1\"),\n",
    "        pyq.CSWAP(0, (1, 2)),\n",
    "        pyq.CRX(1, 2, \"theta_2\"),\n",
    "        pyq.CPHASE(1, 2, \"theta_3\"),\n",
    "        pyq.CNOT(0, 1),\n",
    "        #pyq.Toffoli((0, 1), 2),\n",
    "    ]\n",
    "\n",
    "    circ = QuantumCircuit(n_qubits, ops)\n",
    "\n",
    "    return circ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb1066c-def9-40b2-a050-44e462389059",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 5\n",
    "dtype = torch.complex128\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40cfeaf4-dc56-4f16-9b6c-fe0a28d2cdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charles.moussa/Library/Application Support/hatch/env/virtual/pyqtorch/Gy8xvlfd/pyqtorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1144: UserWarning: Complex modules are a new feature under active development whose design may change, and some modules might not work as expected when using complex tensors as parameters or buffers. Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml if a complex module does not work as expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    " \n",
    "obs2 = Observable(pyq.Add([\n",
    "    pyq.Y(4),\n",
    "    pyq.Scale(pyq.Y(3), torch.tensor(0.8823 + 0.0j)),\n",
    "    pyq.Y(4),\n",
    "    pyq.Scale(pyq.Z(1), torch.tensor(0.9150 + 0.0j)),\n",
    "    pyq.Scale(pyq.Y(2), torch.tensor(0.3829 + 0.0j)),\n",
    "    pyq.Sequence([pyq.Z(4),pyq.X(3),]),\n",
    "    pyq.Scale(pyq.Sequence([pyq.X(0),pyq.Y(4)]), torch.tensor(0.9513 + 0.0j)),\n",
    "    pyq.Sequence([pyq.X(1),pyq.X(4),]),\n",
    "    pyq.Scale(pyq.Sequence([pyq.X(4),pyq.Z(1)]), torch.tensor(0.3904 + 0.0j)),\n",
    "    pyq.Scale(pyq.Sequence([pyq.Z(0),pyq.Z(3)]), torch.tensor(0.6009 + 0.0j)),\n",
    "    \n",
    "])).to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "962e9daf-ce21-4dfb-8f5d-95c24a65450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "circ = circuit_gpsr(n_qubits).to(dtype)\n",
    "\n",
    "values = {\n",
    "    op.param_name: torch.rand(\n",
    "        batch_size, requires_grad=True, dtype=COMPLEX_TO_REAL_DTYPES[dtype]\n",
    "    )\n",
    "    for op in circ.flatten()\n",
    "    if isinstance(op, Parametric) and isinstance(op.param_name, str)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d545e1ee-47fd-4926-9d14-81683abd105d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'theta_0': tensor([0.0582, 0.0629, 0.1236], dtype=torch.float64, requires_grad=True),\n",
       " 'theta_1': tensor([0.0526, 0.5262, 0.4768], dtype=torch.float64, requires_grad=True),\n",
       " 'theta_2': tensor([0.9552, 0.9288, 0.0835], dtype=torch.float64, requires_grad=True),\n",
       " 'theta_3': tensor([0.1326, 0.1571, 0.3754], dtype=torch.float64, requires_grad=True)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ca38aa0-2513-4860-ae02-fdbcbf57bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = pyq.random_state(n_qubits, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c5b32a1-6ccb-4a46-902b-0f4ccb191ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Apply adjoint\n",
    "exp_ad = expectation(circ, state, values, obs2, DiffMode.AD)\n",
    "grad_ad = torch.autograd.grad(\n",
    "    exp_ad, tuple(values.values()), torch.ones_like(exp_ad), create_graph=True\n",
    ")\n",
    "\n",
    "# Apply PSR\n",
    "exp_gpsr = expectation(circ, state, values, obs2, DiffMode.GPSR)\n",
    "grad_gpsr = torch.autograd.grad(\n",
    "    exp_gpsr, tuple(values.values()), torch.ones_like(exp_gpsr), create_graph=True\n",
    ")\n",
    "\n",
    "exp_gpsr_sampled = expectation(\n",
    "    circ,\n",
    "    state,\n",
    "    values,\n",
    "    obs2,\n",
    "    DiffMode.GPSR,\n",
    "    n_shots=100000,\n",
    ")\n",
    "grad_gpsr_sampled = torch.autograd.grad(\n",
    "    exp_gpsr_sampled,\n",
    "    tuple(values.values()),\n",
    "    torch.ones_like(exp_gpsr_sampled),\n",
    "    create_graph=True,\n",
    ")\n",
    "assert torch.allclose(exp_gpsr, exp_gpsr_sampled, atol=1e-01)\n",
    "\n",
    "atol = 1.0e-05\n",
    "\n",
    "# first order checks\n",
    "\n",
    "for i in range(len(grad_ad)):\n",
    "    assert torch.allclose(grad_ad[i], grad_gpsr[i], atol=atol)\n",
    "    assert torch.allclose(\n",
    "        grad_ad[i], grad_gpsr_sampled[i], atol=GRADCHECK_sampling_ATOL\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a72324b0-1b96-480e-a986-141b8d564c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.5767, -0.6116, -0.7841], dtype=torch.float64,\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([-0.5767, -0.6116, -0.7841], dtype=torch.float64,\n",
       "        grad_fn=<PSRExpectationBackward>),\n",
       " tensor([-0.5946, -0.6123, -0.7743], dtype=torch.float64,\n",
       "        grad_fn=<PSRExpectationBackward>))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ad, exp_gpsr, exp_gpsr_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0948a118-ddb6-4e10-a9b2-be21d46bbbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([0.2755, 0.2619, 0.3279], dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       "  tensor([-0.0713, -0.0417, -0.0978], dtype=torch.float64,\n",
       "         grad_fn=<SelectBackward0>),\n",
       "  tensor([0.1615, 0.1911, 0.1711], dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       "  tensor([-0.1700, -0.1699, -0.1076], dtype=torch.float64,\n",
       "         grad_fn=<SelectBackward0>)),\n",
       " (tensor([0.2827, 0.2601, 0.3312], dtype=torch.float64, grad_fn=<ViewBackward0>),\n",
       "  tensor([-0.0632, -0.0340, -0.1070], dtype=torch.float64,\n",
       "         grad_fn=<ViewBackward0>),\n",
       "  tensor([0.1462, 0.1751, 0.1985], dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       "  tensor([-0.1695, -0.1677, -0.1084], dtype=torch.float64,\n",
       "         grad_fn=<ViewBackward0>)))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_ad, grad_gpsr_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d6670-fb8e-46e8-ba02-8f190cb1751d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d0e03-3de2-4d11-9f1b-45028930806d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
