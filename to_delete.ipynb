{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyQTorch logger successfully setup with log level 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9320], dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd.gradcheck\n",
    "\n",
    "import pyqtorch as pyq\n",
    "from pyqtorch.embed import ConcretizedCallable, Embedding\n",
    "# name0, fn0 = \"fn0\", ConcretizedCallable(\"sin\", [\"x\"])\n",
    "name1, fn1 = \"fn1\", ConcretizedCallable(\"mul\", [3, \"x\"])\n",
    "# name2, fn2 = \"fn2\", ConcretizedCallable(\"mul\", [\"fn1\", 2.0])\n",
    "# name3, fn3 = \"fn3\", ConcretizedCallable(\"log\", [\"fn2\"])\n",
    "embedding = pyq.Embedding(\n",
    "    # vparam_names=[\"x\"],\n",
    "    fparam_names=[\"x\"],\n",
    "    var_to_call={name1: fn1},\n",
    "    # var_to_call={name0: fn0, name1: fn1, name2: fn2, name3: fn3},\n",
    ")\n",
    "rx = pyq.RX(0, param_name=name1)\n",
    "# cry = pyq.CRY(0, 1, param_name=name1)\n",
    "# phase = pyq.PHASE(1, param_name=name2)\n",
    "# ry = pyq.RY(1, param_name=name3)\n",
    "# cnot = pyq.CNOT(1, 2)\n",
    "ops = [rx]\n",
    "# ops = [rx, cry, phase, ry, cnot]\n",
    "n_qubits = 1\n",
    "circ = pyq.QuantumCircuit(n_qubits, ops)\n",
    "obs = pyq.Observable([pyq.Z(0)])\n",
    "\n",
    "state = pyq.zero_state(n_qubits)\n",
    "\n",
    "x = torch.tensor(0.1236, requires_grad=True) #torch.rand(1, requires_grad=True)\n",
    "# y = torch.rand(1, requires_grad=True)\n",
    "\n",
    "values_ad = {\"x\": x}\n",
    "embedded_params = embedding(values_ad)\n",
    "exp_val = pyq.expectation(circ, state, embedded_params, obs, embedding=embedding)\n",
    "\n",
    "print(exp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(torch.tensor(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "a = import_module(\"pyqtorch.utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "heaviside() missing 2 required positional arguments: 'x' and 'vals'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaviside\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: heaviside() missing 2 required positional arguments: 'x' and 'vals'"
     ]
    }
   ],
   "source": [
    "a.heaviside()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0.3781], requires_grad=True),\n",
       " 'y': tensor([0.0050], requires_grad=True),\n",
       " 'fn0': tensor([0.3691], grad_fn=<SinBackward0>),\n",
       " 'fn1': tensor([0.0019], grad_fn=<MulBackward0>),\n",
       " 'fn2': tensor([0.0037], grad_fn=<MulBackward0>),\n",
       " 'fn3': tensor([-5.5958], grad_fn=<LogBackward0>)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqtorch import zero_state\n",
    "from pyqtorch.utils import SolverType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = 20.0\n",
    "param_y = 2.0\n",
    "param_x = 5.0\n",
    "sigma_x = torch.tensor([[0.0, 1.0], [1.0, 0.0]])\n",
    "sigma_y = torch.tensor([[0.0, -1.0j], [1.0j, 0.0]])\n",
    "\n",
    "\n",
    "def hamiltonian_t(t: float) -> torch.Tensor:\n",
    "    t = torch.as_tensor(t)\n",
    "    return omega * (\n",
    "        param_y * torch.sin(t) * torch.kron(sigma_x, torch.eye(2))\n",
    "        + param_x * t**2 * torch.kron(torch.eye(2), sigma_y)\n",
    "    ).to(torch.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000+0.0000j, 0.0000-4.0000j, 7.9468+0.0000j, 0.0000+0.0000j],\n",
       "        [0.0000+4.0000j, 0.0000+0.0000j, 0.0000+0.0000j, 7.9468+0.0000j],\n",
       "        [7.9468+0.0000j, 0.0000+0.0000j, 0.0000+0.0000j, 0.0000-4.0000j],\n",
       "        [0.0000+0.0000j, 7.9468+0.0000j, 0.0000+4.0000j, 0.0000+0.0000j]],\n",
       "       dtype=torch.complex128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltonian_t(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.+0.j],\n",
       "         [0.+0.j]],\n",
       "\n",
       "        [[0.+0.j],\n",
       "         [0.+0.j]]], dtype=torch.complex128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_state(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyqtorch as pyq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_t, sin_fn = \"sin_t\", ConcretizedCallable(\"sin\", [\"t\"])\n",
    "t_sq, t_sq_fn = \"t_sq\", ConcretizedCallable(\"mul\", [1.0, \"t\"])\n",
    "\n",
    "generator = pyq.Scale(\n",
    "    pyq.Add([\n",
    "        pyq.Scale(\n",
    "            pyq.Scale(\n",
    "                pyq.X(0),\n",
    "                sin_t\n",
    "            ),\n",
    "            param_y\n",
    "        ),\n",
    "        pyq.Scale(\n",
    "            pyq.Scale(\n",
    "                pyq.Y(1),\n",
    "                t_sq\n",
    "            ),\n",
    "            param_x\n",
    "        ),\n",
    "    ]),\n",
    "    omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.+1.j)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(-1+0j) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_pyq = pyq.sqrt(pyq.sin(\"x\")) + pyq.cos(\"r\") * (1.0 / pyq.log(\"z\") * \"y\")\n",
    "# expr_pyq = pyq.cos(\"z\") ** pyq.log(1.5 / (1.0 + (2.0 * pyq.sin(\"x\")) + \"y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_funcs(expr, independent_args=set()):\n",
    "    fn_name = expr.call_name\n",
    "    # print(\"function:\", expr.call_name, \"; function argument\")\n",
    "    abstract_args = expr.abstract_args\n",
    "    print(f\"[{fn_name}] args: {[arg.call_name if isinstance(arg, ConcretizedCallable) else arg for arg in abstract_args]}\")\n",
    "    if len(abstract_args) == 1 and isinstance(abstract_args[0], str):\n",
    "        independent_args.add(abstract_args[0])\n",
    "        print(\"[0] independent arg:\", abstract_args[0])\n",
    "        print(\"---------------\")\n",
    "    else:\n",
    "        \n",
    "        for arg in abstract_args:\n",
    "            if isinstance(arg, ConcretizedCallable):\n",
    "                # print(\"function:\", arg.call_name)\n",
    "                get_funcs(arg)\n",
    "            else:\n",
    "                print(\"[1] independent arg:\", arg)\n",
    "                print('---------------')\n",
    "\n",
    "    return independent_args\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_independent_args(cc: ConcretizedCallable) -> set:\n",
    "    # if out is None:\n",
    "    out = set()\n",
    "    if len(cc.abstract_args) == 1 and isinstance(cc.abstract_args[0], str):\n",
    "        print(\"independent arg:\", cc.abstract_args[0])\n",
    "        return set([cc.abstract_args[0]])\n",
    "    else:\n",
    "        # out = set()\n",
    "        for arg in cc.abstract_args:\n",
    "            if isinstance(arg, ConcretizedCallable):\n",
    "                res = _get_independent_args(arg)\n",
    "                print(\"got:\", res, \"out:\", out)\n",
    "                out.add(res)\n",
    "            else:\n",
    "                print(\"arg:\", arg, out)\n",
    "                if isinstance(arg, str):\n",
    "                    out.add(arg)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mul] args: [3.0, 'x']\n",
      "[1] independent arg: 3.0\n",
      "---------------\n",
      "[1] independent arg: x\n",
      "---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_funcs(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = set()\n",
    "st.add(\"a\")\n",
    "st.add(\"b\")\n",
    "st.add(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arg: 3.0 set()\n",
      "arg: x set()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_independent_args(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z', 'x', 'r']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_pyq.independent_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = ConcretizedCallable(\"mul\", [3.0, \"x\"])\n",
    "cc.independent_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_funcs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_funcs\u001b[49m(expr_pyq)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_funcs' is not defined"
     ]
    }
   ],
   "source": [
    "get_funcs(expr_pyq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "x, y, z = symbols('x y z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pow(sin(Symbol('x')), Rational(1, 2))\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_sympy = sqrt(sin(x))\n",
    "# expr_sympy = cos(z) ** log(1.5 / (1.0 + (2 * sin(x)) + y))\n",
    "srepr(expr_sympy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9535708427429199"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = {\"x\": torch.tensor(2.0), \"y\": torch.tensor(0.5), \"z\": torch.tensor(0.2)}\n",
    "expr_pyq(vals).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.5$"
      ],
      "text/plain": [
       "0.500000000000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rational(\"1/2\").evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.953570881909511$"
      ],
      "text/plain": [
       "0.953570881909511"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_sympy.subs({x: vals[\"x\"], y: vals[\"y\"], z: vals[\"z\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce, partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    Pow: \"pow\",\n",
    "    cos: \"cos\",\n",
    "    Add: \"add\",\n",
    "    Mul: \"mul\",\n",
    "    sin: \"sin\",\n",
    "    log: \"log\",\n",
    "    # sqrt: \"sqrt\",\n",
    "    # Rational: \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sympy_to_pyq(expr):\n",
    "    print(\"recursion level start...\")\n",
    "    print(\"func:\", expr.func, \"|\", expr.args)\n",
    "\n",
    "    if len(expr.args) == 0:\n",
    "        print(\"returning arg from base case:\")\n",
    "        res = float(expr) if str(expr).replace('.', '', 1).replace('-', '', 1).isdigit() else str(expr)\n",
    "        if isinstance(res, str):\n",
    "            if \"/\" in res:\n",
    "                # found a rational\n",
    "                res = float(Rational(res).evalf())\n",
    "            if \"fix\" in res:\n",
    "                # found a fixed parameter - convert to float\n",
    "                res = float(res.split(\"_\")[1])\n",
    "        print(res, type(res))\n",
    "        return res\n",
    "\n",
    "    all_results = []\n",
    "    for i, arg in enumerate(expr.args):\n",
    "        print(f\"--- {i} all func args:\", expr.args)\n",
    "        res = sympy_to_pyq(arg)\n",
    "\n",
    "        print(f\"[{i}] returned arg:\", res)\n",
    "\n",
    "\n",
    "        all_results.append(res)\n",
    "    \n",
    "    print(\"args:\")\n",
    "    print(all_results)\n",
    "\n",
    "    # if isinstance(expr.func, Rational):\n",
    "\n",
    "\n",
    "    if len(all_results) > 2:\n",
    "        fn = lambda x, y: partial(ConcretizedCallable, call_name=mapping[expr.func])(abstract_args=[x, y])\n",
    "        cc = reduce(fn, all_results)\n",
    "    else:\n",
    "        # a = \", \".join(tmp) if len(tmp) > 1 else str(tmp[0])\n",
    "        cc = ConcretizedCallable(mapping[expr.func], all_results)\n",
    "\n",
    "    print(\"Concretized callable object:\")\n",
    "    print(cc)\n",
    "    return cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_qadence = omega * (y * sin(x) + x * (z**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recursion level start...\n",
      "func: <class 'sympy.core.add.Add'> | (20.0*x*z**2, 20.0*y*sin(x))\n",
      "--- 0 all func args: (20.0*x*z**2, 20.0*y*sin(x))\n",
      "recursion level start...\n",
      "func: <class 'sympy.core.mul.Mul'> | (20.0000000000000, x, z**2)\n",
      "--- 0 all func args: (20.0000000000000, x, z**2)\n",
      "recursion level start...\n",
      "func: <class 'sympy.core.numbers.Float'> | ()\n",
      "returning arg from base case:\n",
      "20.0 <class 'float'>\n",
      "[0] returned arg: 20.0\n",
      "--- 1 all func args: (20.0000000000000, x, z**2)\n",
      "recursion level start...\n",
      "func: <class 'sympy.core.symbol.Symbol'> | ()\n",
      "returning arg from base case:\n",
      "x <class 'str'>\n",
      "[1] returned arg: x\n",
      "--- 2 all func args: (20.0000000000000, x, z**2)\n",
      "recursion level start...\n",
      "func: <class 'sympy.core.power.Pow'> | (z, 2)\n",
      "--- 0 all func args: (z, 2)\n",
      "recursion level start...\n",
      "func: <class 'sympy.core.symbol.Symbol'> | ()\n",
      "returning arg from base case:\n",
      "z <class 'str'>\n",
      "[0] returned arg: z\n",
      "--- 1 all func args: (z, 2)\n",
      "recursion level start...\n",
      "func: <class 'sympy.core.numbers.Integer'> | ()\n",
      "returning arg from base case:\n",
      "2.0 <class 'float'>\n",
      "[1] returned arg: 2.0\n",
      "args:\n",
      "['z', 2.0]\n",
      "Concretized callable object:\n",
      "<pyqtorch.embed.ConcretizedCallable object at 0x761c783302b0>\n",
      "[2] returned arg: <pyqtorch.embed.ConcretizedCallable object at 0x761c783302b0>\n",
      "args:\n",
      "[20.0, 'x', <pyqtorch.embed.ConcretizedCallable object at 0x761c783302b0>]\n",
      "Concretized callable object:\n",
      "<pyqtorch.embed.ConcretizedCallable object at 0x761c783302e0>\n",
      "[0] returned arg: <pyqtorch.embed.ConcretizedCallable object at 0x761c783302e0>\n",
      "--- 1 all func args: (20.0*x*z**2, 20.0*y*sin(x))\n",
      "recursion level start...\n",
      "func: <class 'sympy.core.mul.Mul'> | (20.0000000000000, y, sin(x))\n",
      "--- 0 all func args: (20.0000000000000, y, sin(x))\n",
      "recursion level start...\n",
      "func: <class 'sympy.core.numbers.Float'> | ()\n",
      "returning arg from base case:\n",
      "20.0 <class 'float'>\n",
      "[0] returned arg: 20.0\n",
      "--- 1 all func args: (20.0000000000000, y, sin(x))\n",
      "recursion level start...\n",
      "func: <class 'sympy.core.symbol.Symbol'> | ()\n",
      "returning arg from base case:\n",
      "y <class 'str'>\n",
      "[1] returned arg: y\n",
      "--- 2 all func args: (20.0000000000000, y, sin(x))\n",
      "recursion level start...\n",
      "func: sin | (x,)\n",
      "--- 0 all func args: (x,)\n",
      "recursion level start...\n",
      "func: <class 'sympy.core.symbol.Symbol'> | ()\n",
      "returning arg from base case:\n",
      "x <class 'str'>\n",
      "[0] returned arg: x\n",
      "args:\n",
      "['x']\n",
      "Concretized callable object:\n",
      "<pyqtorch.embed.ConcretizedCallable object at 0x761c783304f0>\n",
      "[2] returned arg: <pyqtorch.embed.ConcretizedCallable object at 0x761c783304f0>\n",
      "args:\n",
      "[20.0, 'y', <pyqtorch.embed.ConcretizedCallable object at 0x761c783304f0>]\n",
      "Concretized callable object:\n",
      "<pyqtorch.embed.ConcretizedCallable object at 0x761c78330310>\n",
      "[1] returned arg: <pyqtorch.embed.ConcretizedCallable object at 0x761c78330310>\n",
      "args:\n",
      "[<pyqtorch.embed.ConcretizedCallable object at 0x761c783302e0>, <pyqtorch.embed.ConcretizedCallable object at 0x761c78330310>]\n",
      "Concretized callable object:\n",
      "<pyqtorch.embed.ConcretizedCallable object at 0x761c78330040>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10.6930)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = sympy_to_pyq(generator_qadence)\n",
    "cc(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = lambda x, y: partial(ConcretizedCallable, call_name=\"add\")(abstract_args=[x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add['x', 'y'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn(*[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add[add['x', 'y']), 'z'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(fn, [\"x\", \"y\", \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pow] args: ['cos', 'log']\n",
      "[cos] args: ['z']\n",
      "final arg: z\n",
      "---------------\n",
      "[log] args: ['mul']\n",
      "[mul] args: [1.5, 'pow']\n",
      "independent arg: 1.5\n",
      "---------------\n",
      "[pow] args: ['add', -1.0]\n",
      "[add] args: [1.0, 'mul']\n",
      "independent arg: 1.0\n",
      "---------------\n",
      "[mul] args: [2.0, 'sin']\n",
      "independent arg: 2.0\n",
      "---------------\n",
      "[sin] args: ['x']\n",
      "final arg: x\n",
      "---------------\n",
      "independent arg: -1.0\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "get_funcs(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0128)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = pyq.Scale(pyq.X(0), sin_t)\n",
    "\n",
    "embedding = pyq.Embedding(\n",
    "    tparam_name=\"t\",\n",
    "    var_to_call={sin_t: sin_fn, t_sq: t_sq_fn},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000+0.0000j, 0.0000-4.0000j, 7.9468+0.0000j, 0.0000+0.0000j],\n",
       "        [0.0000+4.0000j, 0.0000+0.0000j, 0.0000+0.0000j, 7.9468+0.0000j],\n",
       "        [7.9468+0.0000j, 0.0000+0.0000j, 0.0000+0.0000j, 0.0000-4.0000j],\n",
       "        [0.0000+0.0000j, 7.9468+0.0000j, 0.0000+4.0000j, 0.0000+0.0000j]],\n",
       "       dtype=torch.complex128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = {\"t\": torch.tensor(0.2)}\n",
    "generator.tensor(values=vals, embedding=embedding, full_support=[0,1]).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_params = embedding(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000+0.j],\n",
       "         [0.5985+0.j]],\n",
       "\n",
       "        [[0.5985+0.j],\n",
       "         [0.0000+0.j]]], dtype=torch.complex128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.tensor(values=embedded_params, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqtorch.primitives import Parametric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_parametrized(operation: pyq.Sequence) -> bool:\n",
    "    params = []\n",
    "    for m in operation.modules():\n",
    "        if isinstance(m, (pyq.Scale, Parametric)):\n",
    "            params.append(m.param_name)\n",
    "\n",
    "    res = False\n",
    "    if any([isinstance(p, str) for p in params]):\n",
    "        res = True\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_parametrized(pyq.Sequence([pyq.RX(0, \"x\"), pyq.RY(1, \"y\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, d = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000+0.0000j, 0.0000-4.0000j, 7.9468+0.0000j, 0.0000+0.0000j],\n",
       "        [0.0000+4.0000j, 0.0000+0.0000j, 0.0000+0.0000j, 7.9468+0.0000j],\n",
       "        [7.9468+0.0000j, 0.0000+0.0000j, 0.0000+0.0000j, 0.0000-4.0000j],\n",
       "        [0.0000+0.0000j, 7.9468+0.0000j, 0.0000+4.0000j, 0.0000+0.0000j]],\n",
       "       dtype=torch.complex128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = {\"t\": torch.tensor(0.3)}\n",
    "\n",
    "embedded_params = embedding(values)\n",
    "\n",
    "\n",
    "reembedded_params = embedding.reembed_tparam(embedded_params, torch.tensor(0.2))\n",
    "\n",
    "generator.tensor(values=reembedded_params, embedding=embedding).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0951+0.0000j],\n",
      "        [-0.1566+0.0000j],\n",
      "        [ 0.0000-0.5102j],\n",
      "        [ 0.0000-0.8403j]], dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "duration = 0.5\n",
    "n_steps = 1000\n",
    "\n",
    "# simulate with torch-based solver\n",
    "psi0_torch = zero_state(2).reshape(-1, 1)\n",
    "t_points = torch.linspace(0, duration, n_steps)\n",
    "state_torch = pyq.sesolve(hamiltonian_t, psi0_torch, t_points, SolverType.DP5_SE).states[-1]\n",
    "print(state_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Taking support from generator and ignoring qubit_support input.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sin_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m])\n\u001b[1;32m     13\u001b[0m time_symbol \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m hamiltonian_evolution \u001b[38;5;241m=\u001b[39m \u001b[43mHamiltonianEvolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_symbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqubit_support\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqubit_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mis_time_dependent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSolverType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDP5_SE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Starting from a uniform state\u001b[39;00m\n\u001b[1;32m     19\u001b[0m psi_start \u001b[38;5;241m=\u001b[39m zero_state(n_qubits)\n",
      "File \u001b[0;32m~/Projects/pasqal/pyqtorch/pyqtorch/hamiltonians/evolution.py:194\u001b[0m, in \u001b[0;36mHamiltonianEvolution.__init__\u001b[0;34m(self, generator, time, qubit_support, generator_parametric, cache_length, is_time_dependent, duration, steps, solver)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator_type \u001b[38;5;241m=\u001b[39m GeneratorType\u001b[38;5;241m.\u001b[39mPARAMETRIC_OPERATION\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m         generator \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    193\u001b[0m             Primitive(\n\u001b[0;32m--> 194\u001b[0m                 \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    195\u001b[0m                 generator\u001b[38;5;241m.\u001b[39mqubit_support,\n\u001b[1;32m    196\u001b[0m             )\n\u001b[1;32m    197\u001b[0m         ]\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator_type \u001b[38;5;241m=\u001b[39m GeneratorType\u001b[38;5;241m.\u001b[39mOPERATION\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/pasqal/pyqtorch/pyqtorch/composite/compose.py:98\u001b[0m, in \u001b[0;36mScale.tensor\u001b[0;34m(self, values, embedding, full_support)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03mGet the corresponding unitary over n_qubits.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    The unitary representation.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m scale \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m     values[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_name]\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_name, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_name\n\u001b[1;32m     97\u001b[0m )\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scale \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_support\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/pasqal/pyqtorch/pyqtorch/composite/compose.py:180\u001b[0m, in \u001b[0;36mAdd.tensor\u001b[0;34m(self, values, embedding, full_support)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpanding tensor operation requires a `full_support` argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlarger than or equal to the `qubit_support`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m mat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    178\u001b[0m     (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(full_support), \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(full_support), \u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    179\u001b[0m )\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_support\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/pasqal/pyqtorch/pyqtorch/composite/compose.py:182\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpanding tensor operation requires a `full_support` argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlarger than or equal to the `qubit_support`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m mat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    178\u001b[0m     (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(full_support), \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(full_support), \u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    179\u001b[0m )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(\n\u001b[1;32m    181\u001b[0m     add,\n\u001b[0;32m--> 182\u001b[0m     (\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_support\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperations),\n\u001b[1;32m    183\u001b[0m     mat,\n\u001b[1;32m    184\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/pasqal/pyqtorch/pyqtorch/composite/compose.py:98\u001b[0m, in \u001b[0;36mScale.tensor\u001b[0;34m(self, values, embedding, full_support)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03mGet the corresponding unitary over n_qubits.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    The unitary representation.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m scale \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m     values[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_name]\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_name, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_name\n\u001b[1;32m     97\u001b[0m )\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scale \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_support\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/pasqal/pyqtorch/pyqtorch/composite/compose.py:94\u001b[0m, in \u001b[0;36mScale.tensor\u001b[0;34m(self, values, embedding, full_support)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     78\u001b[0m     values: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(),\n\u001b[1;32m     79\u001b[0m     embedding: Embedding \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m     full_support: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     81\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Operator:\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    Get the corresponding unitary over n_qubits.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m        The unitary representation.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     scale \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 94\u001b[0m         \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_name, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_name\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scale \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperations[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtensor(values, embedding, full_support)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sin_x'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pyqtorch import uniform_state, HamiltonianEvolution\n",
    "from pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n",
    "\n",
    "n_qubits = 2\n",
    "qubit_targets = list(range(n_qubits))\n",
    "\n",
    "# Random hermitian hamiltonian\n",
    "matrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\n",
    "hermitian_matrix = matrix + matrix.T.conj()\n",
    "\n",
    "time = torch.tensor([1.0])\n",
    "time_symbol = \"t\"\n",
    "\n",
    "hamiltonian_evolution = HamiltonianEvolution(generator=generator, time=time_symbol, qubit_support=qubit_targets, \n",
    "                                             is_time_dependent=True, duration=duration, steps=n_steps, solver=SolverType.DP5_SE)\n",
    "\n",
    "# Starting from a uniform state\n",
    "psi_start = zero_state(n_qubits)\n",
    "\n",
    "# Returns the evolved state\n",
    "psi_end = hamiltonian_evolution(state=psi_start, values={time_symbol: time}, embedding=embedding)\n",
    "\n",
    "print(psi_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1987)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/vytautas/Downloads/task_all_annotations_2024_08_26_07_25_47_coco 1 (1).0/annotations/instances_all.json\", \"r\") as f:\n",
    "    a = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'name': 'lav', 'supercategory': ''},\n",
       " {'id': 2, 'name': 'civ-car', 'supercategory': ''},\n",
       " {'id': 3, 'name': 'infantry', 'supercategory': ''},\n",
       " {'id': 4, 'name': 'mlrs', 'supercategory': ''},\n",
       " {'id': 5, 'name': 'Tank', 'supercategory': ''},\n",
       " {'id': 6, 'name': 'Truck', 'supercategory': ''},\n",
       " {'id': 7, 'name': 'apc', 'supercategory': ''},\n",
       " {'id': 8, 'name': 'army-truck', 'supercategory': ''},\n",
       " {'id': 9, 'name': 'artillery-gun', 'supercategory': ''},\n",
       " {'id': 10, 'name': 'car', 'supercategory': ''},\n",
       " {'id': 11, 'name': 'humvee', 'supercategory': ''},\n",
       " {'id': 12, 'name': 'military-vehicle', 'supercategory': ''},\n",
       " {'id': 13, 'name': 'person', 'supercategory': ''},\n",
       " {'id': 14, 'name': 'pickup', 'supercategory': ''},\n",
       " {'id': 15, 'name': 'rocket-artillery', 'supercategory': ''},\n",
       " {'id': 16, 'name': 'soldier', 'supercategory': ''},\n",
       " {'id': 17, 'name': 'tank', 'supercategory': ''},\n",
       " {'id': 18, 'name': 'truck', 'supercategory': ''},\n",
       " {'id': 19, 'name': 'van', 'supercategory': ''},\n",
       " {'id': 20, 'name': 'vehicle', 'supercategory': ''}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annot in a[\"annotations\"]:\n",
    "    if annot[\"category_id\"] == 10:\n",
    "        annot[\"category_id\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/vytautas/Downloads/task_all_annotations_2024_08_26_07_25_47_coco 1 (1).0/annotations/instances_all.json\", \"w\") as f:\n",
    "    json.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyqtorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
