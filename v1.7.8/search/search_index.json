{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to pyqtorch","text":"<p>pyqtorch is a state vector simulator designed for quantum machine learning written in PyTorch. It allows for building fully differentiable quantum circuits comprised of both digital and analog operations using a intuitive torch.nn.Module-based API. It can be used standalone as shown in these docs, or through our framework for quantum programming: Qadence.</p>"},{"location":"#setup","title":"Setup","text":"<p>To install <code>pyqtorch</code> , you can go into any virtual environment of your choice and install it normally with <code>pip</code>:</p> <pre><code>pip install pyqtorch\n</code></pre>"},{"location":"#digital-operations","title":"Digital Operations","text":"<p><code>pyqtorch</code> implements a large selection of both primitive and parametric single to n-qubit, digital quantum gates.</p> <p>Let's have a look at primitive gates first.</p> <pre><code>import torch\nfrom pyqtorch import X, CNOT, random_state\n\nx = X(0)\nstate = random_state(n_qubits=2)\n\nnew_state = x(state)\n\ncnot = CNOT(0,1)\nnew_state= cnot(state)\n</code></pre> <p>Parametric gates can be initialized with or without a <code>param_name</code>. In the former case, a dictionary containing the <code>param_name</code> and a <code>torch.Tensor</code> for the parameter is expected when calling the forward method of the gate.</p> <pre><code>import torch\nfrom pyqtorch import X, RX, CNOT, CRX, random_state\n\nstate = random_state(n_qubits=2)\n\nrx_with_param = RX(0, 'theta')\n\ntheta = torch.rand(1)\nvalues = {'theta': theta}\nnew_state = rx_with_param(state, values)\n\ncrx = CRX(0, 1, 'theta')\nnew_state = crx(state, values)\n</code></pre> <p>However, if you want to run a quick state vector simulation, you can initialize parametric gates without passing a <code>param_name</code>, in which case the forward method of the gate will simply expect a <code>torch.Tensor</code>.</p> <pre><code>import torch\nfrom pyqtorch import RX, random_state\n\nstate = random_state(n_qubits=2)\nrx = RX(0)\nnew_state = rx(state, torch.rand(1))\n</code></pre>"},{"location":"#analog-operations","title":"Analog Operations","text":"<p>An analog operation is one whose unitary is best described by the evolution of some hermitian generator, or Hamiltonian, acting on an arbitrary number of qubits. For a time-independent generator \\(\\mathcal{H}\\) and some time variable \\(t\\), the evolution operator is \\(\\exp(-i\\mathcal{H}t)\\).</p> <p><code>pyqtorch</code> also contains a <code>analog</code> module which allows for global state evolution through the <code>HamiltonianEvolution</code> class. There exists several ways to pass a generator, and we present them in Analog Operations. Below, we show an example where the generator \\(\\mathcal{H}\\) is an arbitrary tensor. To build arbitrary Pauli hamiltonians, we recommend using Qadence.</p> <pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution, is_normalized\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n\nn_qubits = 4\n\n# Random hermitian hamiltonian\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nhermitian_matrix = matrix + matrix.T.conj()\n\n# To be evolved for a batch of times\nt_list = torch.tensor([0.0, 0.5, 1.0, 2.0])\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_matrix, t_list, [i for i in range(n_qubits)])\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns an evolved state at each time value\npsi_end = hamiltonian_evolution(\n    state = psi_start)\n\nassert is_normalized(psi_end, atol=1e-05)\n</code></pre> <p>Dimensionless units</p> <p>The quantity \\(\\mathcal{H}t\\) has to be considered dimensionless for exponentiation in <code>pyqtorch</code>.</p>"},{"location":"#circuits","title":"Circuits","text":"<p>Using digital and analog operations, you can can build fully differentiable quantum circuits using the <code>QuantumCircuit</code> class; note that the default differentiation mode in pyqtorch is using torch.autograd.</p> <pre><code>import torch\nimport pyqtorch as pyq\n\nrx = pyq.RX(0, param_name=\"theta\")\ny = pyq.Y(0)\ncnot = pyq.CNOT(0, 1)\nops = [rx, y, cnot]\nn_qubits = 2\ncirc = pyq.QuantumCircuit(n_qubits, ops)\nstate = pyq.random_state(n_qubits)\ntheta = torch.rand(1, requires_grad=True)\nobs = pyq.Observable(pyq.Z(0))\nexpval = pyq.expectation(circ, state, {\"theta\": theta}, obs)\ndfdtheta = torch.autograd.grad(expval, theta, torch.ones_like(expval))\n</code></pre>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CONTRIBUTING/","title":"How to Contribute","text":"<p>We're grateful for your interest in participating in pyqtorch! Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an Issue or Proposing a Feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to PyQ, feel free to create an issue on pyqtorch's GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a Pull Request","text":"<p>We're excited that you're eager to contribute to pyqtorch! To contribute, fork the <code>main</code> branch of pyqtorch repository and once you are satisfied with your feature and all the tests pass create a Pull Request.</p> <p>Here's the process for making a contribution:</p> <p>Click the \"Fork\" button at the upper right corner of the repo page to create a new GitHub repo at <code>https://github.com/USERNAME/pyqtorch</code>, where <code>USERNAME</code> is your GitHub ID. Then, <code>cd</code> into the directory where you want to place your new fork and clone it:</p> <pre><code>git clone https://github.com/USERNAME/pyqtorch.git\n</code></pre> <p>Next, navigate to your new pyqtorch fork directory and mark the main pyqtorch repository as the <code>upstream</code>:</p> <pre><code>git remote add upstream https://github.com/pasqal-io/pyqtorch.git\n</code></pre>"},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments:</p> <p>To develop within pyqtorch, use: <pre><code>pip install hatch\nhatch -v shell\n</code></pre></p> <p>To run pyqtorch tests, use:</p> <pre><code>hatch -e tests run test\n</code></pre> <p>If you don't want to use <code>hatch</code>, you can use the environment manager of your choice (e.g. Conda) and execute the following:</p> <pre><code>pip install pytest\n\npip install -e .\npytest\n</code></pre>"},{"location":"CONTRIBUTING/#useful-things-for-your-workflow-linting-and-testing","title":"Useful Things for your workflow: Linting and Testing","text":"<p>Use <code>pre-commit</code> hooks to make sure that the code is properly linted before pushing a new commit. Make sure that the unit tests and type checks are passing since the merge request will not be accepted if the automatic CI/CD pipeline do not pass.</p> <p>Without <code>hatch</code>:</p> <pre><code>pip install pytest\n\npip install -e .\npip install pre-commit\npre-commit install\npre-commit run --all-files\npytest\n</code></pre> <p>And with <code>hatch</code>:</p> <pre><code>hatch -e tests run pre-commit run --all-files\nhatch -e tests run test\n</code></pre> <p>Make sure your docs build too!</p> <p>With <code>hatch</code>:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"analog/","title":"Analog Operations","text":""},{"location":"analog/#analog-operations","title":"Analog Operations","text":"<p>An analog operation is one whose unitary is best described by the evolution of some hermitian generator, or Hamiltonian, acting on an arbitrary number of qubits. For a time-independent generator \\(\\mathcal{H}\\) and some time variable \\(t\\), the evolution operator is \\(\\exp(-i\\mathcal{H}t)\\). <code>pyqtorch</code> provides the HamiltonianEvolution class to initialize analog operations. There exists several ways to pass a generator, and we present them next.</p> <p>Dimensionless units</p> <p>The quantity \\(\\mathcal{H}t\\) has to be dimensionless for exponentiation in PyQTorch.</p>"},{"location":"analog/#tensor-generator","title":"Tensor generator","text":"<p>The first case of generator we can provide is simply an arbitrary hermitian tensor. Note we can use a string for defining the time evolution as a parameter, instead of directly passing a tensor.</p> <pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n\nn_qubits = 2\nqubit_targets = list(range(n_qubits))\n\n# Random hermitian hamiltonian\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nhermitian_matrix = matrix + matrix.T.conj()\n\ntime = torch.tensor([1.0])\ntime_symbol = \"t\"\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_matrix, time_symbol, qubit_targets)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start, values={time_symbol: time})\n\nprint(psi_end)\n</code></pre>   tensor([[[ 0.0993+0.2018j],          [-0.2131+0.4646j]],          [[-0.0261+0.4976j],          [-0.1327+0.6498j]]], dtype=torch.complex128)"},{"location":"analog/#symbol-generator","title":"Symbol generator","text":"<p>We can also have a symbol generator to be replaced later by any hermitian matrix. and in this case we use a string symbol to instantiate <code>HamiltonianEvolution</code>.</p> <pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n\nn_qubits = 2\nqubit_targets = list(range(n_qubits))\n\n# Symbol hamiltonian\nhermitian_symbol = \"h\"\n\ntime = torch.tensor([1.0])\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_symbol, time, qubit_targets)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Set the value for h\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nH = matrix + matrix.T.conj()\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start, values={hermitian_symbol: H})\n\nprint(psi_end)\n</code></pre>   tensor([[[-0.3125+0.3507j],          [ 0.0096+0.5820j]],          [[-0.1989+0.3154j],          [-0.1599+0.5252j]]], dtype=torch.complex128)"},{"location":"analog/#sequence-generator","title":"Sequence generator","text":"<p>The generator can be also a sequence of operators such as a quantum circuit:</p> <pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution, X, Y\nfrom pyqtorch import Add, QuantumCircuit\n\nn_qubits = 2\n\nops = [X, Y] * 2\nqubit_targets = list(range(n_qubits))\ngenerator = QuantumCircuit(\n    n_qubits,\n    [\n        Add([op(q) for op, q in zip(ops, qubit_targets)]),\n        *[op(q) for op, q in zip(ops, qubit_targets)],\n    ],\n)\n\ntime = torch.tensor([1.0])\n\nhamiltonian_evolution = HamiltonianEvolution(generator, time, qubit_targets)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start)\n\nprint(psi_end)\n</code></pre>   tensor([[[-0.0814+0.1267j],          [ 0.3733-0.5814j]],          [[-0.0814+0.1267j],          [ 0.3733-0.5814j]]], dtype=torch.complex128)"},{"location":"analog/#batched-execution","title":"Batched execution","text":"<p>We also allow for different ways to run analog operations on batched inputs. We can have batched evolution times, or batched generators. Below we show a few examples.</p>"},{"location":"analog/#batched-evolution-times","title":"Batched evolution times","text":"<pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n\nn_qubits = 2\nqubit_targets = list(range(n_qubits))\n\n# Random hermitian hamiltonian\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nhermitian_matrix = matrix + matrix.T.conj()\n\ntimes = torch.tensor([0.25, 0.5, 0.75, 1.0])\ntime_symbol = \"t\"\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_matrix, time_symbol, qubit_targets)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start, values={time_symbol: times})\n\nprint(psi_end.size())\n</code></pre>   torch.Size([2, 2, 4])"},{"location":"analog/#batched-generators","title":"Batched generators","text":"<pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n\nn_qubits = 2\nqubit_targets = list(range(n_qubits))\n\n# Random hermitian hamiltonian\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nH = matrix + matrix.T.conj()\nhermitian_batch = torch.stack((H, H.conj()), dim=2)\n\ntime = torch.tensor([1.0])\ntime_symbol = \"t\"\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_batch, time_symbol, qubit_targets)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start, values={time_symbol: time})\n\nprint(psi_end.size())\n</code></pre>   torch.Size([2, 2, 2])"},{"location":"api/","title":"API","text":"<p><code>pyqtorch</code> exposes three API endpoints called <code>run</code>, <code>sample</code> and <code>expectation</code>. Please note that all endpoints expect a <code>QuantumCircuit</code> object.</p>"},{"location":"api/#run","title":"run","text":"<p>Sequentially apply each operation in <code>circuit</code> to an input state <code>state</code> given parameter values <code>values</code>, perform an optional <code>embedding</code> on <code>values</code> and return an output state.</p> <p>Parameters:</p> Name Type Description Default <code>circuit</code> <code>QuantumCircuit</code> <p>A pyqtorch.QuantumCircuit instance.</p> required <code>state</code> <code>Tensor</code> <p>A torch.Tensor of shape [2, 2, ..., batch_size].</p> <code>None</code> <code>values</code> <code>dict[str, Tensor] | None</code> <p>A dictionary containing &lt;'parameter_name': torch.Tensor&gt; pairs denoting     the current parameter values for each parameter in <code>circuit</code>.</p> <code>None</code> <code>embedding</code> <code>Embedding | None</code> <p>An optional instance of <code>Embedding</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A torch.Tensor of shape [2, 2, ..., batch_size].</p> <p>Example:</p> <pre><code>from torch import rand\nfrom pyqtorch import QuantumCircuit, RY, random_state, run\n\nn_qubits = 2\ncirc = QuantumCircuit(n_qubits, [RY(0, 'theta')])\nstate = random_state(n_qubits)\nrun(circ, state, {'theta': rand(1)})\n</code></pre> Source code in <code>pyqtorch/api.py</code> <pre><code>def run(\n    circuit: QuantumCircuit,\n    state: Tensor = None,\n    values: dict[str, Tensor] | None = None,\n    embedding: Embedding | None = None,\n) -&gt; Tensor:\n    \"\"\"Sequentially apply each operation in `circuit` to an input state `state`\n    given parameter values `values`, perform an optional `embedding` on `values`\n    and return an output state.\n\n    Arguments:\n        circuit: A pyqtorch.QuantumCircuit instance.\n        state: A torch.Tensor of shape [2, 2, ..., batch_size].\n        values: A dictionary containing &lt;'parameter_name': torch.Tensor&gt; pairs denoting\n                the current parameter values for each parameter in `circuit`.\n        embedding: An optional instance of `Embedding`.\n\n    Returns:\n         A torch.Tensor of shape [2, 2, ..., batch_size].\n\n    Example:\n\n    ```python exec=\"on\" source=\"material-block\" html=\"1\"\n    from torch import rand\n    from pyqtorch import QuantumCircuit, RY, random_state, run\n\n    n_qubits = 2\n    circ = QuantumCircuit(n_qubits, [RY(0, 'theta')])\n    state = random_state(n_qubits)\n    run(circ, state, {'theta': rand(1)})\n    ```\n    \"\"\"\n    values = values or dict()\n    logger.debug(f\"Running circuit {circuit} on state {state} and values {values}.\")\n    return circuit.run(state=state, values=values, embedding=embedding)\n</code></pre>"},{"location":"api/#sample","title":"sample","text":"<p>Sample from <code>circuit</code> given an input state <code>state</code> given current parameter values <code>values</code>, perform an optional <code>embedding</code> on <code>values</code> and return a list Counter objects mapping from . <p>Parameters:</p> Name Type Description Default <code>circuit</code> <code>QuantumCircuit</code> <p>A pyqtorch.QuantumCircuit instance.</p> required <code>state</code> <code>Tensor</code> <p>A torch.Tensor of shape [2, 2, ..., batch_size].</p> <code>None</code> <code>values</code> <code>dict[str, Tensor] | None</code> <p>A dictionary containing &lt;'parameter_name': torch.Tensor&gt; pairs     denoting the current parameter values for each parameter in <code>circuit</code>.</p> <code>None</code> <code>n_shots</code> <code>int</code> <p>A positive int denoting the number of requested samples.</p> <code>1000</code> <code>embedding</code> <code>Embedding | None</code> <p>An optional instance of <code>Embedding</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Counter]</code> <p>A list of Counter objects containing  pairs. <p>Example:</p> <pre><code>from torch import rand\nfrom pyqtorch import random_state, sample, QuantumCircuit, RY\n\nn_qubits = 2\ncirc = QuantumCircuit(n_qubits, [RY(0, 'theta')])\nstate = random_state(n_qubits)\nsample(circ, state, {'theta': rand(1)}, n_shots=1000)[0]\n</code></pre> Source code in <code>pyqtorch/api.py</code> <pre><code>def sample(\n    circuit: QuantumCircuit,\n    state: Tensor = None,\n    values: dict[str, Tensor] | None = None,\n    n_shots: int = 1000,\n    embedding: Embedding | None = None,\n) -&gt; list[Counter]:\n    \"\"\"Sample from `circuit` given an input state `state` given\n    current parameter values `values`, perform an optional `embedding`\n    on `values` and return a list Counter objects mapping from\n    &lt;bitstring: num_samples&gt;.\n\n    Arguments:\n        circuit: A pyqtorch.QuantumCircuit instance.\n        state: A torch.Tensor of shape [2, 2, ..., batch_size].\n        values: A dictionary containing &lt;'parameter_name': torch.Tensor&gt; pairs\n                denoting the current parameter values for each parameter in `circuit`.\n        n_shots: A positive int denoting the number of requested samples.\n        embedding: An optional instance of `Embedding`.\n\n    Returns:\n         A list of Counter objects containing &lt;bitstring: num_samples&gt; pairs.\n\n    Example:\n\n    ```python exec=\"on\" source=\"material-block\" html=\"1\"\n    from torch import rand\n    from pyqtorch import random_state, sample, QuantumCircuit, RY\n\n    n_qubits = 2\n    circ = QuantumCircuit(n_qubits, [RY(0, 'theta')])\n    state = random_state(n_qubits)\n    sample(circ, state, {'theta': rand(1)}, n_shots=1000)[0]\n    ```\n    \"\"\"\n    values = values or dict()\n    logger.debug(\n        f\"Sampling circuit {circuit} on state {state} and values {values} with n_shots {n_shots}.\"\n    )\n    return circuit.sample(\n        state=state, values=values, n_shots=n_shots, embedding=embedding\n    )\n</code></pre>"},{"location":"api/#expectation","title":"expectation","text":"<p>Compute the expectation value of <code>circuit</code> given a <code>state</code>, parameter values <code>values</code> and an <code>observable</code> and optionally compute gradients using diff_mode.</p> <p>Parameters:</p> Name Type Description Default <code>circuit</code> <code>QuantumCircuit</code> <p>A pyqtorch.QuantumCircuit instance.</p> required <code>state</code> <code>Tensor</code> <p>A torch.Tensor of shape [2, 2, ..., batch_size].</p> <code>None</code> <code>values</code> <code>dict[str, Tensor] | dict[str, dict[str, Tensor]] | None</code> <p>A dictionary containing &lt;'parameter_name': torch.Tensor&gt; pairs     denoting the current parameter values for each parameter in <code>circuit</code>.     Note it can include also values for the observables, but differentiation will     not separate gradients.     To do so, we should provide values as a dict of dict[str, Tensor]     with two keys: <code>circuit</code> and <code>observables</code>.</p> <code>None</code> <code>observable</code> <code>Observable</code> <p>A pyq.Observable instance.</p> <code>None</code> <code>diff_mode</code> <code>DiffMode</code> <p>The differentiation mode.</p> <code>AD</code> <code>n_shots</code> <code>int | None</code> <p>Number of shots for estimating expectation values.         Only used with DiffMode.GPSR or DiffMode.AD.</p> <code>None</code> <code>embedding</code> <code>Embedding | None</code> <p>An optional instance of <code>Embedding</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>An expectation value.</p> <p>Example:</p> <pre><code>from torch import pi, ones_like, tensor\nfrom pyqtorch import random_state, RY, expectation, DiffMode, Observable, Add, Z, QuantumCircuit\nfrom torch.autograd import grad\n\nn_qubits = 2\ncirc = QuantumCircuit(n_qubits, [RY(0, 'theta')])\nstate = random_state(n_qubits)\ntheta = tensor(pi, requires_grad=True)\nobservable = Observable(Add([Z(i) for i in range(n_qubits)]))\nexpval = expectation(circ, state, {'theta': theta}, observable, diff_mode = DiffMode.ADJOINT)\ndfdtheta= grad(expval, theta, ones_like(expval))[0]\n</code></pre> Source code in <code>pyqtorch/api.py</code> <pre><code>def expectation(\n    circuit: QuantumCircuit,\n    state: Tensor = None,\n    values: dict[str, Tensor] | dict[str, dict[str, Tensor]] | None = None,\n    observable: Observable = None,  # type: ignore[assignment]\n    diff_mode: DiffMode = DiffMode.AD,\n    n_shots: int | None = None,\n    embedding: Embedding | None = None,\n) -&gt; Tensor:\n    \"\"\"Compute the expectation value of `circuit` given a `state`,\n    parameter values `values` and an `observable`\n    and optionally compute gradients using diff_mode.\n\n    Arguments:\n        circuit: A pyqtorch.QuantumCircuit instance.\n        state: A torch.Tensor of shape [2, 2, ..., batch_size].\n        values: A dictionary containing &lt;'parameter_name': torch.Tensor&gt; pairs\n                denoting the current parameter values for each parameter in `circuit`.\n                Note it can include also values for the observables, but differentiation will\n                not separate gradients.\n                To do so, we should provide values as a dict of dict[str, Tensor]\n                with two keys: `circuit` and `observables`.\n        observable: A pyq.Observable instance.\n        diff_mode: The differentiation mode.\n        n_shots: Number of shots for estimating expectation values.\n                    Only used with DiffMode.GPSR or DiffMode.AD.\n        embedding: An optional instance of `Embedding`.\n\n    Returns:\n        An expectation value.\n\n    Example:\n\n    ```python exec=\"on\" source=\"material-block\" html=\"1\"\n    from torch import pi, ones_like, tensor\n    from pyqtorch import random_state, RY, expectation, DiffMode, Observable, Add, Z, QuantumCircuit\n    from torch.autograd import grad\n\n    n_qubits = 2\n    circ = QuantumCircuit(n_qubits, [RY(0, 'theta')])\n    state = random_state(n_qubits)\n    theta = tensor(pi, requires_grad=True)\n    observable = Observable(Add([Z(i) for i in range(n_qubits)]))\n    expval = expectation(circ, state, {'theta': theta}, observable, diff_mode = DiffMode.ADJOINT)\n    dfdtheta= grad(expval, theta, ones_like(expval))[0]\n    ```\n    \"\"\"\n    values = values or dict()\n\n    if embedding is not None and diff_mode != DiffMode.AD:\n        raise NotImplementedError(\"Only diff_mode AD supports embedding\")\n    logger.debug(\n        f\"Computing expectation of circuit {circuit} on state {state}, values {values},\\\n          given observable {observable} and diff_mode {diff_mode}.\"\n    )\n    if observable is None:\n        logger.error(\"Please provide an observable to compute expectation.\")\n\n    if state is None:\n        state = circuit.init_state(batch_size=1)\n\n    expectation_fn = analytical_expectation\n    if n_shots is not None:\n        if isinstance(n_shots, int) and n_shots &gt; 0:\n            expectation_fn = partial(sampled_expectation, n_shots=n_shots)\n        else:\n            logger.error(\"Please provide a 'n_shots' in options of type 'int'.\")\n\n    if diff_mode == DiffMode.AD:\n        return expectation_fn(\n            circuit,\n            state,\n            observable,\n            values,\n            embedding,\n        )\n    elif diff_mode == DiffMode.ADJOINT:\n        return AdjointExpectation.apply(\n            circuit,\n            state,\n            observable,\n            embedding,\n            values.keys(),\n            *values.values(),\n        )\n    elif diff_mode == DiffMode.GPSR:\n        check_support_psr(circuit)\n        return PSRExpectation.apply(\n            circuit,\n            state,\n            observable,\n            embedding,\n            expectation_fn,\n            values.keys(),\n            *values.values(),\n        )\n    else:\n        logger.error(f\"Requested diff_mode '{diff_mode}' not supported.\")\n</code></pre>"},{"location":"cuda_debugging/","title":"CUDA Profiling and debugging","text":"<p>To debug your quantum programs on <code>CUDA</code> devices, <code>pyqtorch</code> offers a <code>DEBUG</code> mode, which can be activated via setting the <code>PYQ_LOG_LEVEL</code> environment variable.</p> <pre><code>export PYQ_LOG_LEVEL=DEBUG\n</code></pre> <p>Before running your script, make sure to install the following packages:</p> <p><pre><code>pip install nvidia-pyindex\npip install nvidia-dlprof[pytorch]\n</code></pre> For more information, check the dlprof docs.</p>"},{"location":"differentiation/","title":"Differentiation","text":""},{"location":"differentiation/#differentiation","title":"Differentiation","text":"<p><code>pyqtorch</code> also offers several differentiation modes to compute gradients which can be accessed through the <code>expectation</code> API. Simply pass one of three <code>DiffMode</code> options to the <code>diff_mode</code> argument. The default is <code>ad</code>.</p>"},{"location":"differentiation/#automatic-differentiation-diffmodead","title":"Automatic Differentiation (DiffMode.AD)","text":"<p>The default differentation mode of <code>pyqtorch</code>, torch.autograd. It uses the <code>torch</code> native automatic differentiation engine which tracks operations on <code>torch.Tensor</code> objects by constructing a computational graph to perform chain rules for derivatives calculations.</p>"},{"location":"differentiation/#adjoint-differentiation-diffmodeadjoint","title":"Adjoint Differentiation (DiffMode.ADJOINT)","text":"<p>The adjoint differentiation mode computes first-order gradients by only requiring at most three states in memory in <code>O(P)</code> time where <code>P</code> is the number of parameters in a circuit.</p>"},{"location":"differentiation/#generalized-parameter-shift-rules-diffmodegpsr","title":"Generalized Parameter-Shift rules (DiffMode.GPSR)","text":"<p>The Generalized parameter shift rule (GPSR mode) is an extension of the well known parameter shift rule (PSR) algorithm to arbitrary quantum operations. Indeed, PSR only works for quantum operations whose generator has a single gap in its eigenvalue spectrum, GPSR extending to multi-gap.</p> <p>Usage restrictions</p> <p>At the moment, circuits with one or more <code>Scale</code> or <code>HamiltonianEvolution</code> with parametric generators operations are not supported. They should be handled differently as GPSR requires operations to be of the form presented below.</p> <p>For this, we define the differentiable function as quantum expectation value</p> \\[ f(x) = \\left\\langle 0\\right|\\hat{U}^{\\dagger}(x)\\hat{C}\\hat{U}(x)\\left|0\\right\\rangle \\] <p>where \\(\\hat{U}(x)={\\rm exp}{\\left( -i\\frac{x}{2}\\hat{G}\\right)}\\) is the quantum evolution operator with generator \\(\\hat{G}\\) representing the structure of the underlying quantum circuit and \\(\\hat{C}\\) is the cost operator. Then using the eigenvalue spectrum \\(\\lambda_n\\) of the generator \\(\\hat{G}\\) we calculate the full set of corresponding unique non-zero spectral gaps \\({ \\Delta_s\\}\\) (differences between eigenvalues). It can be shown that the final expression of derivative of \\(f(x)\\) is then given by the following expression:</p> \\[ \\begin{equation} \\frac{{\\rm d}f\\left(x\\right)}{{\\rm d}x}=\\overset{S}{\\underset{s=1}{\\sum}}\\Delta_{s}R_{s}, \\end{equation} \\] <p>where \\(S\\) is the number of unique non-zero spectral gaps and \\(R_s\\) are real quantities that are solutions of a system of linear equations</p> \\[ \\begin{equation} \\begin{cases} F_{1} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{1}\\Delta_{s}}{2}\\right)R_{s},\\\\ F_{2} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{2}\\Delta_{s}}{2}\\right)R_{s},\\\\  &amp; ...\\\\ F_{S} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{M}\\Delta_{s}}{2}\\right)R_{s}. \\end{cases} \\end{equation} \\] <p>Here \\(F_s=f(x+\\delta_s)-f(x-\\delta_s)\\) denotes the difference between values of functions evaluated at shifted arguments \\(x\\pm\\delta_s\\).</p> <p>Using GPSR with HamiltonianEvolution</p> <p>GPSR works with the formalism above-presented, which corresponds to many parametric operations such as rotation gates. For HamiltonianEvolution, since the factor 1/2 is missing, to allow GPSR differentiation, we multiply by 2 the spectral gaps. Also we use a shift prefactor of 0.5 for multi-gap GPSR or 0.5 divided by the spectral gap for single-gap GPSR.</p>"},{"location":"differentiation/#examples","title":"Examples","text":""},{"location":"differentiation/#circuit-parameters-differentiation","title":"Circuit parameters differentiation","text":"<p>We show below a code example with several differentiation methods for circuit parameters:</p> <pre><code>import pyqtorch as pyq\nimport torch\nfrom pyqtorch.utils import DiffMode\n\nn_qubits = 3\nbatch_size = 1\n\nry = pyq.RY(0, param_name=\"x\")\ncnot = pyq.CNOT(1, 2)\nops = [ry, cnot]\nn_qubits = 3\ncirc = pyq.QuantumCircuit(n_qubits, ops)\n\nobs = pyq.Observable(pyq.Z(0))\nstate = pyq.zero_state(n_qubits)\n\nvalues_ad = {\"x\": torch.tensor([torch.pi / 2], requires_grad=True)}\nvalues_adjoint = {\"x\": torch.tensor([torch.pi / 2], requires_grad=True)}\nvalues_gpsr = {\"x\": torch.tensor([torch.pi / 2], requires_grad=True)}\n\nexp_ad = pyq.expectation(circ, state, values_ad, obs, DiffMode.AD)\nexp_adjoint = pyq.expectation(circ, state, values_adjoint, obs, DiffMode.ADJOINT)\nexp_gpsr = pyq.expectation(circ, state, values_gpsr, obs, DiffMode.GPSR)\n\ndfdx_ad = torch.autograd.grad(exp_ad, tuple(values_ad.values()), torch.ones_like(exp_ad))\n\ndfdx_adjoint = torch.autograd.grad(\n    exp_adjoint, tuple(values_adjoint.values()), torch.ones_like(exp_adjoint)\n)\n\ndfdx_gpsr = torch.autograd.grad(\n    exp_gpsr, tuple(values_gpsr.values()), torch.ones_like(exp_gpsr)\n)\n\nassert len(dfdx_ad) == len(dfdx_adjoint) == len(dfdx_gpsr)\nfor i in range(len(dfdx_ad)):\n    assert torch.allclose(dfdx_ad[i], dfdx_adjoint[i])\n    assert torch.allclose(dfdx_ad[i], dfdx_gpsr[i])\n</code></pre>"},{"location":"differentiation/#parametrized-observable-differentiation","title":"Parametrized observable differentiation","text":"<p>To allow differentiating observable parameters only, we need to specify the <code>values</code> argument as a dictionary with two keys <code>circuit</code> and <code>observables</code>, each being a dictionary of corresponding parameters and values, as follows:</p> <pre><code>obs = pyq.Observable(pyq.RZ(0, \"obs\"))\nvalues_obs = {\"obs\": torch.tensor([torch.pi / 2], requires_grad=True)}\nvalues = {\"circuit\": values_ad, \"observables\": values_obs}\nexp_ad_separate = pyq.expectation(circ, state, values, obs, DiffMode.AD)\ngrad_ad_obs = torch.autograd.grad(\n    exp_ad_separate, tuple(values_obs.values()), torch.ones_like(exp_ad_separate)\n)\nassert len(grad_ad_obs) == len(obs.params)\n</code></pre>"},{"location":"dropout/","title":"Quantum Dropout","text":""},{"location":"dropout/#fitting-a-noisy-sinusoid-with-quantum-dropout","title":"Fitting a noisy sinusoid with quantum dropout","text":"<p>Here we will demonstrate an implemention quantum dropout, for the case of fitting a noisy sine function. To show the usefulness of dropout for quantum neural networks (QNNs), we shall compare the performance of a QNN with dropout and one without.</p> <p>Firstly, we define the dataset that we will perform regression on, this function is \\(sin(\\pi x)+\\epsilon\\), where \\(x\\in\\reals\\) and \\(\\epsilon\\) is noise sampled from a normal distribution which is then added to each point.</p> <pre><code>from __future__ import annotations\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport numpy as np\nimport torch\nfrom torch import manual_seed, optim, tensor\n\nimport pyqtorch as pyq\nfrom pyqtorch.circuit import DropoutQuantumCircuit\nfrom pyqtorch.primitives import Parametric\nfrom pyqtorch.utils import DropoutMode\n\nseed = 70\nmanual_seed(seed)\nnp.random.seed(seed)\n\n# choose device and hyperparameters\n\ndevice = torch.device(\"cpu\")\nn_qubits = 2 # a greater performance difference is observed with 5 or more qubits\ndepth = 5 # a greater performance difference is observed at depth 10\nlr = 0.01\nn_points = 20\nepochs = 100 # a greater performance difference is observed at 200-250 epochs of training\ndropout_prob = 0.06\nnoise = 0.4\n\ndef sin_dataset(dataset_size: int = 100, test_size: float = 0.4, noise: float = 0.4):\n    \"\"\"Generates points (x,y) which follow sin(\u03c0x)+\u03f5,\n        where epsilon is noise randomly sampled from the normal\n        distribution for each datapoint.\n    Args:\n        dataset_size (int): total number of points. Defaults to 100.\n        test_size (float): fraction of points for testing. Defaults to 0.4.\n        noise (float): standard deviation of added noise. Defaults to 0.4.\n    Returns:\n        data (tuple): data divided into training and testing\n    \"\"\"\n    x_ax = np.linspace(-1, 1, dataset_size)\n    y = np.sin(x_ax * np.pi)\n    noise = np.random.normal(0, 0.5, y.shape) * noise\n    y += noise\n\n    # permuting the points around before dividing into train and test sets.\n    rng = np.random.default_rng(seed)\n    indices = rng.permutation(dataset_size)\n    n_test = int(dataset_size * test_size)\n    n_train = int(dataset_size * (1 - test_size))\n    test_indices = indices[:n_test]\n    train_indices = indices[n_test : (n_test + n_train)]\n    x_train, x_test, y_train, y_test = (\n        x_ax[train_indices],\n        x_ax[test_indices],\n        y[train_indices],\n        y[test_indices],\n    )\n\n    x_train = x_train.reshape(-1, 1)\n    x_test = x_test.reshape(-1, 1)\n    y_train = y_train.reshape(-1, 1)\n    y_test = y_test.reshape(-1, 1)\n    return x_train, x_test, y_train, y_test\n\n\n# generates points following sin(\u03c0x)+\u03f5, split into training and testing sets.\nx_train, x_test, y_train, y_test = sin_dataset(dataset_size=n_points, test_size=0.25, noise=0.4)\n</code></pre> <p>We can now visualise the function we will train QNNs to learn.</p> <pre><code>fig, ax = plt.subplots()\nplt.plot(x_train, y_train, \"o\", label=\"training\")\nplt.plot(x_test, y_test, \"o\", label=\"testing\")\nplt.plot(\n    np.linspace(-1, 1, 100),\n    [np.sin(x * np.pi) for x in np.linspace(-1, 1, 100)],\n    linestyle=\"dotted\",\n    label=r\"$\\sin(x)$\",\n)\nplt.ylabel(r\"$y = \\sin(\\pi\\cdot x) + \\epsilon$\")\nplt.xlabel(r\"$x$\")\nax.xaxis.set_major_locator(ticker.MultipleLocator(0.5))\nax.yaxis.set_major_locator(ticker.MultipleLocator(0.5))\nplt.legend()\n</code></pre> 2025-06-17T13:11:41.297826 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>Since our QNN can only output values between -1 and 1 we need to scale the data to be between these values.</p> <pre><code>class MinMaxScaler:\n    \"\"\"A class which scales data to be within a chosen range\"\"\"\n\n    def __init__(self, feature_range: tuple =(0, 1)):\n        self.feature_range = feature_range\n        self.min = None\n        self.scale = None\n\n    def fit(self, X):\n        self.min = X.min(axis=0)\n        self.scale = X.max(axis=0) - self.min\n        self.scale[self.scale == 0] = 1  # Avoid division by zero for constant features\n\n    def transform(self, X):\n        X_scaled = (X - self.min) / self.scale\n        X_scaled = (\n            X_scaled * (self.feature_range[1] - self.feature_range[0]) + self.feature_range[0]\n        )\n        return X_scaled\n\n    def fit_transform(self, X):\n        self.fit(X)\n        return self.transform(X)\n\n    def inverse_transform(self, X_scaled):\n        X = (X_scaled - self.feature_range[0]) / (self.feature_range[1] - self.feature_range[0])\n        X = X * self.scale + self.min\n        return X\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\ny_train = scaler.fit_transform(y_train)\ny_test = scaler.transform(y_test)\n</code></pre> <p>Now we need to construct our QNNs, they are comprised of feature maps and an ansatz. The ansatz contains CNOT gates with nearest neighbour entanglement after every rotation gate. The feature map contains two rotation gates RY and RZ, taking as rotation angles \\(\\arcsin(x)\\) and \\(\\arccos(x^2)\\) respectively.</p> <pre><code>def hea_ansatz(n_qubits, layer):\n    \"\"\"creates an ansatz which performs RX, RZ, RX rotations on each qubit,\n    which nearest neighbour CNOT gates interpersed between each rotational gate.\"\"\"\n    ops = []\n    for i in range(n_qubits):\n        ops.append(pyq.RX(i, param_name=f\"theta_{i}{layer}{0}\"))\n\n    for j in range(n_qubits - 1):\n        ops.append(pyq.CNOT(control=j, target=j + 1))\n\n    for i in range(n_qubits):\n        ops.append(pyq.RZ(i, param_name=f\"theta_{i}{layer}{1}\"))\n\n    for j in range(n_qubits - 1):\n        ops.append(pyq.CNOT(control=j, target=j + 1))\n\n    for i in range(n_qubits):\n        ops.append(pyq.RX(i, param_name=f\"theta_{i}{layer}{2}\"))\n\n    for j in range(n_qubits - 1):\n        ops.append(pyq.CNOT(control=j, target=j + 1))\n    return ops\n\n# the two feature maps we will be using\ndef fm1(n_qubits):\n    return [pyq.RY(i, \"x1\") for i in range(n_qubits)]\n\n\ndef fm2(n_qubits):\n    return [pyq.RZ(i, \"x2\") for i in range(n_qubits)]\n\n# The class which constructs QNNs\nclass QuantumModelBase(torch.nn.Module):\n    def __init__(self, n_qubits, n_layers, device):\n        super().__init__()\n        self.n_qubits = n_qubits\n        self.n_layers = n_layers\n        self.device = device\n\n        self.embedding1 = fm1(n_qubits=n_qubits)\n        self.embedding2 = fm2(n_qubits=n_qubits)\n\n        self.params = torch.nn.ParameterDict()\n        operations = self.build_operations()\n        self.circuit = self.build_circuit(operations)\n        self.observable = pyq.Observable([pyq.Z(i) for i in range(n_qubits)]).to(\n            device, dtype=torch.complex64\n        )\n        self.params = self.params.to(device=device, dtype=torch.float32)\n\n    def build_operations(self):\n        \"\"\"defines operations for the quantum circuit and trainable parameters.\"\"\"\n        operations = []\n        for i in range(self.n_layers):\n            operations += self.embedding1 + self.embedding2\n            layer_i_ansatz = hea_ansatz(n_qubits=n_qubits, layer=i)\n            operations += layer_i_ansatz\n            for op in layer_i_ansatz:\n                if isinstance(op, Parametric):\n                    self.params[f\"{op.param_name}\"] = torch.randn(1, requires_grad=True)\n\n        return operations\n\n    def build_circuit(self, operations):\n        \"\"\"constructs a QuantumCircuit object and puts it on device.\"\"\"\n        return pyq.QuantumCircuit(\n            n_qubits=self.n_qubits,\n            operations=operations,\n        ).to(device=self.device, dtype=torch.complex64)\n\n    def forward(self, x):\n        \"\"\"the forward pass for the QNN\"\"\"\n        x = x.flatten()\n        x_1 = {\"x1\": torch.asin(x)}\n        x_2 = {\"x2\": torch.acos(x**2)}\n        state = self.circuit.init_state(batch_size=int(x.shape[0]))\n\n        out = pyq.expectation(\n            circuit=self.circuit,\n            state=state,\n            values={**self.params, **x_1, **x_2},\n            observable=self.observable,\n        )\n\n        return out\n\n# first we will define a QNN which is overparameterised with no dropout.\nmodel = QuantumModelBase(n_qubits=n_qubits, n_layers=depth, device=device)\n# define the corresponding optimizer for the problem\nopt = optim.Adam(model.parameters(), lr=lr)\n</code></pre> <p>We now wish to train the QNN to learn the noisy sinusoidal function we have defined. This function will return the loss curves for the train and test sets.</p> <pre><code>def train(model, opt, x_train, y_train, x_test, y_test, epochs, device):\n    # lists which will store losses for train and tests sets as we train.\n    train_loss_history = []\n    validation_loss_history = []\n\n    x_test = tensor(x_test).to(device, dtype=torch.float32)\n    y_test = (\n        tensor(y_test)\n        .to(device, dtype=torch.float32)\n        .reshape(\n            -1,\n        )\n    )\n\n    x_train = tensor(x_train).to(device, dtype=torch.float32)\n    y_train = (\n        tensor(y_train)\n        .to(device, dtype=torch.float32)\n        .reshape(\n            -1,\n        )\n    )\n\n    # we will be using the mean squared error as our loss function.\n    cost_fn = torch.nn.MSELoss()\n\n    for epoch in range(epochs):\n        model.train()\n\n        opt.zero_grad()\n        y_preds = model(x_train)\n        train_loss = cost_fn(y_preds, y_train.flatten())\n        train_loss.backward()\n        opt.step()\n\n        # no dropout is performed during evaluation of the model.\n        model.eval()\n        train_preds = model(x_train)\n        train_loss = cost_fn(train_preds, y_train.flatten()).detach().cpu().numpy()\n\n        test_preds = model(x_test)\n        test_loss = cost_fn(test_preds, y_test.flatten()).detach().cpu().numpy()\n\n        train_loss_history.append(train_loss)\n        validation_loss_history.append(test_loss)\n\n        # log performance every 100 epochs.\n        if epoch % 100 == 0:\n            print(f\"epoch: {epoch}, train loss {train_loss}, val loss: {test_loss}\")\n\n    return train_loss_history, validation_loss_history\n\n# train the vanilla QNN, extracting the training and testing loss curves\nno_dropout_train_loss_hist, no_dropout_test_loss_hist = train(\n    model=model,\n    opt=opt,\n    x_train=x_train,\n    y_train=y_train,\n    x_test=x_test,\n    y_test=y_test,\n    epochs=epochs,\n    device=device,\n)\n</code></pre>   epoch: 0, train loss 0.9277403950691223, val loss: 0.7329995632171631    <p>Next we define a QNN with the same archecture as before but now includes rotational dropout. Rotional dropout will randomly drop single qubit trainable parameterised gates with some probability dropout_prob.</p> <pre><code>class DropoutModel(QuantumModelBase):\n    \"\"\"Inherits from QuantumModelBase but the build_circuit function now creates a circuit which drops certain gates with some probability during training.\"\"\"\n    def __init__(\n        self, n_qubits, n_layers, device, dropout_mode=\"rotational_dropout\", dropout_prob=0.03\n    ):\n        self.dropout_mode = dropout_mode\n        self.dropout_prob = dropout_prob\n        super().__init__(n_qubits, n_layers, device)\n\n    def build_circuit(self, operations):\n        return DropoutQuantumCircuit(\n            n_qubits=self.n_qubits,\n            operations=operations,\n            dropout_mode=self.dropout_mode,\n            dropout_prob=self.dropout_prob,\n        ).to(device=self.device, dtype=torch.complex64)\n\n# Define the QNN with rotational quantum dropout.\nmodel = DropoutModel(\n    n_qubits=n_qubits,\n    n_layers=depth,\n    device=device,\n    dropout_mode=DropoutMode.ROTATIONAL,\n    dropout_prob=dropout_prob,\n)\n\n# Define the corresponding optimiser\nopt = optim.Adam(model.parameters(), lr=lr)\n\n# train the QNN which contains rotational dropout.\ndropout_train_loss_hist, dropout_test_loss_hist = train(\n    model=model,\n    opt=opt,\n    x_train=x_train,\n    y_train=y_train,\n    x_test=x_test,\n    y_test=y_test,\n    epochs=epochs,\n    device=device,\n)\n</code></pre>   epoch: 0, train loss 0.2451528012752533, val loss: 0.47134819626808167    <p>Now that we have trained both a regular QNN and one with rotational quantum dropout, we can visualise the training and testing loss curves. What we observe is the regular QNN performing better on the train set but poorer on the test set. We can attribute this discrepency to the regular QNN overfitting to the noise rather than the true underlying function. The QNN with rotational dropout does no exhibit overfitting and adheres to the true function better, thus performs better on the test set.</p> <pre><code>def plot_results(\n    no_dropout_train_history,\n    no_dropout_test_history,\n    dropout_train_history,\n    dropout_test_history,\n    epochs,\n):\n    fig, ax = plt.subplots(1, 2)\n    plt.subplots_adjust(wspace=0.05)\n    ax[0].set_title(\"MSE train\")\n\n    ax[0].plot(range(epochs), no_dropout_train_history, label=\"no dropout\")\n    ax[0].plot(range(epochs), dropout_train_history, label=\"dropout\")\n\n    ax[1].set_title(\"MSE test\")\n    ax[1].plot(range(epochs), no_dropout_test_history, label=\"no dropout\")\n    ax[1].plot(range(epochs), dropout_test_history, label=\"dropout\")\n\n    ax[0].legend(\n        loc=\"upper center\", bbox_to_anchor=(1.01, 1.25), ncol=4, fancybox=True, shadow=True\n    )\n\n    for ax in ax.flat:\n        ax.set_xlabel(\"Epochs\")\n        ax.set_ylabel(\"MSE\")\n        ax.set_yscale(\"log\")\n        ax.set_ylim([1e-3, 0.6])\n        ax.label_outer()\n\n    plt.subplots_adjust(bottom=0.3)\n\n\n\n# finally we compare the\nplot_results(\n    no_dropout_train_history=no_dropout_train_loss_hist,\n    dropout_train_history=dropout_train_loss_hist,\n    no_dropout_test_history=no_dropout_test_loss_hist,\n    dropout_test_history=dropout_test_loss_hist,\n    epochs=epochs,\n)\n</code></pre> 2025-06-17T13:11:59.286516 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"embed/","title":"Use Arbitrary Expressions as Gate Parameters via Embedding","text":"<p>By default, a <code>Parametric</code> operation expects a <code>values</code> dict with a value for its parameter in the forward-pass when initialized using a <code>str</code> parameter.</p>"},{"location":"embed/#using-arbitrary-expressions-as-parameters","title":"Using arbitrary expressions as parameters","text":"<p><code>pyqtorch</code> allows for using arbitary expressions as parameters, for instance <code>sin(x)</code> where <code>x</code> can be a FeatureParameter. To do so, a name has to be assigned to the outcome of the evaluation of <code>sin(x)</code> and supplied to the <code>pyq.QuantumCircuit</code> within an instance of <code>Embedding</code>.</p>"},{"location":"embed/#creating-parameter-expressions-using-concretizedcallable","title":"Creating parameter expressions using <code>ConcretizedCallable</code>","text":"<p><code>pyq.ConcretizedCallable</code> expects a name for a function and a list of arguments <pre><code>import torch\nimport pyqtorch as pyq\nsin_x, sin_x_fn = 'sin_x', pyq.ConcretizedCallable(call_name = 'sin', abstract_args=['x'])\n# We can now evaluate sin_x_fn using a values dict\nx = torch.rand(1, requires_grad=True)\nvalues = {'x': x}\nresult = sin_x_fn(values)\nprint(torch.autograd.grad(result, x, torch.ones_like(result))[0])\n</code></pre>   tensor([0.9998])   </p>"},{"location":"embed/#interfacing-concretizedcallable-with-quantumcircuit-parameters-via-the-embedding-class","title":"Interfacing <code>ConcretizedCallable</code> with QuantumCircuit parameters via the <code>Embedding</code> class","text":"<p>Lets use <code>sin_x</code> in another callable, so our gate will be parametrized by the result of the expression <code>y * sin(x)</code> where <code>y</code> is trainable and <code>x</code> is a feature parameter. We can tell <code>pyq</code> how to associate each callable with its underlying parameters via the <code>Embedding</code> class which expects arguments regarding what are trainable and non-trainable symbols.</p> <pre><code>mul_sinx_y, mul_sinx_y_fn = 'mul_sinx_y', pyq.ConcretizedCallable(call_name = 'mul', abstract_args=['sin_x', 'y'])\nembedding = pyq.Embedding(vparam_names=['y'], fparam_names=['x'], var_to_call={sin_x: sin_x_fn, mul_sinx_y: mul_sinx_y_fn})\ncirc = pyq.QuantumCircuit(1, [pyq.RX(0, mul_sinx_y)])\nstate= pyq.zero_state(1)\ny = torch.rand(1, requires_grad=True)\nvalues = {'x': x, 'y': y}\nobs = pyq.Observable([pyq.Z(0)])\nexpval = pyq.expectation(circuit=circ, state=state, values=values, observable=obs, diff_mode=pyq.DiffMode.AD, embedding=embedding)\nprint(torch.autograd.grad(expval, (x, y), torch.ones_like(expval)))\n</code></pre>   (tensor([-0.0088]), tensor([-0.0003]))"},{"location":"embed/#tracking-and-reembedding-a-tracked-parameter","title":"Tracking and Reembedding a tracked parameter","text":"<p>For specific usecases, a <code>tparam</code> argument can be passed to the <code>Embedding</code> which tells the class to track the computations depending on it which enables for their efficient recomputation given different values for <code>tparam</code>.</p> <pre><code>v_params = [\"theta\"]\nf_params = [\"x\"]\ntparam = \"t\"\nleaf0, native_call0 = \"%0\", pyq.ConcretizedCallable(\n    \"mul\", [\"x\", \"theta\"], {}\n)\nleaf1, native_call1 = \"%1\", pyq.ConcretizedCallable(\n    \"mul\", [\"t\", \"%0\"], {}\n)\n\nleaf2, native_call2 = \"%2\", pyq.ConcretizedCallable(\"sin\", [\"%1\"], {})\nembedding = pyq.Embedding(\n    v_params,\n    f_params,\n    var_to_call={leaf0: native_call0, leaf1: native_call1, leaf2: native_call2},\n    tparam_name=tparam,\n)\ninputs = {\n    \"x\": torch.rand(1),\n    \"theta\": torch.rand(1),\n    tparam: torch.rand(1),\n}\nall_params = embedding.embed_all(inputs)\nprint(f'{leaf2} value before reembedding: {all_params[leaf2]}')\nnew_tparam_val = torch.rand(1)\nreembedded_params = embedding.reembed_tparam(all_params, new_tparam_val)\nprint(f'{leaf2} value after reembedding: {reembedded_params[leaf2]}')\n</code></pre>   %2 value before reembedding: tensor([0.0767]) %2 value after reembedding: tensor([0.0918])"},{"location":"embed/#see-the-docstrings-for-more-details-and-examples","title":"See the docstrings for more details and examples:","text":""},{"location":"embed/#concretizedcallable","title":"ConcretizedCallable","text":"<p>Transform an abstract function name and arguments into     a callable in a linear algebra engine which can be evaluated     using user input. Arguments:     call_name: The name of the function.     abstract_args: A list of arguments to the function,                    can be numeric types for constants or strings for parameters     instruction_mapping: A dict containing user-passed mappings from a function name                         to its implementation.     engine_name: The name of the framework to use.     device: Which device to use.</p> <p>Example: <pre><code>import torch\n\nfrom pyqtorch.embed import ConcretizedCallable\n\n\nIn [11]: call = ConcretizedCallable('sin', ['x'], engine_name='numpy')\nIn [12]: call({'x': 0.5})\nOut[12]: 0.479425538604203\n\nIn [13]: call = ConcretizedCallable('sin', ['x'], engine_name='torch')\nIn [14]: call({'x': torch.rand(1)})\nOut[14]: tensor([0.5531])\n\nIn [15]: call = ConcretizedCallable('sin', ['x'], engine_name='jax')\nIn [16]: call({'x': 0.5})\nOut[16]: Array(0.47942555, dtype=float32, weak_type=True)\n</code></pre></p> Source code in <code>pyqtorch/embed.py</code> <pre><code>class ConcretizedCallable:\n    \"\"\"Transform an abstract function name and arguments into\n        a callable in a linear algebra engine which can be evaluated\n        using user input.\n    Arguments:\n        call_name: The name of the function.\n        abstract_args: A list of arguments to the function,\n                       can be numeric types for constants or strings for parameters\n        instruction_mapping: A dict containing user-passed mappings from a function name\n                            to its implementation.\n        engine_name: The name of the framework to use.\n        device: Which device to use.\n\n    Example:\n    ```\n    import torch\n\n    from pyqtorch.embed import ConcretizedCallable\n\n\n    In [11]: call = ConcretizedCallable('sin', ['x'], engine_name='numpy')\n    In [12]: call({'x': 0.5})\n    Out[12]: 0.479425538604203\n\n    In [13]: call = ConcretizedCallable('sin', ['x'], engine_name='torch')\n    In [14]: call({'x': torch.rand(1)})\n    Out[14]: tensor([0.5531])\n\n    In [15]: call = ConcretizedCallable('sin', ['x'], engine_name='jax')\n    In [16]: call({'x': 0.5})\n    Out[16]: Array(0.47942555, dtype=float32, weak_type=True)\n    ```\n\n\n\n    \"\"\"\n\n    def __init__(\n        self,\n        call_name: str = \"\",\n        abstract_args: list[str | float | int | complex | ConcretizedCallable] = [\"x\"],\n        instruction_mapping: dict[str, Tuple[str, str]] | None = None,\n        engine_name: str = \"torch\",\n        device: str = \"cpu\",\n        dtype: Any = None,\n    ) -&gt; None:\n        instruction_mapping = instruction_mapping or dict()\n        instruction_mapping = {\n            **instruction_mapping,\n            **DEFAULT_INSTRUCTION_MAPPING[engine_name],\n        }\n        self.call_name = call_name\n        self.abstract_args = abstract_args\n        self.engine_name = engine_name\n        self._device = device\n        self._dtype = dtype\n        self.engine_call = None\n        engine = None\n        if not all(\n            [\n                isinstance(arg, (str, float, int, complex, Tensor, ConcretizedCallable))\n                for arg in abstract_args\n            ]\n        ):\n            raise TypeError(\n                \"Only str, float, int, complex, Tensor or ConcretizedCallable type elements \\\n                are supported for abstract_args\"\n            )\n        try:\n            engine_name, fn_name = ARRAYLIKE_FN_MAP[engine_name]\n            engine = import_module(engine_name)\n            self.arraylike_fn = getattr(engine, fn_name)\n        except (ModuleNotFoundError, ImportError) as e:\n            logger.error(f\"Unable to import {engine_name} due to {e}.\")\n\n        try:\n            self.engine_call = getattr(engine, call_name, None)\n            if self.engine_call is None:\n                mod, fn = instruction_mapping[call_name]\n                self.engine_call = getattr(import_module(mod), fn)\n        except (ImportError, KeyError) as e:\n            logger.error(\n                f\"Requested function {call_name} can not be imported from {engine_name} and is\"\n                + f\" not in instruction_mapping {instruction_mapping} due to {e}.\"\n            )\n\n    def evaluate(self, inputs: dict[str, ArrayLike] | None = None) -&gt; ArrayLike:\n        arraylike_args = []\n        inputs = inputs or dict()\n        for symbol_or_numeric in self.abstract_args:\n            if isinstance(symbol_or_numeric, ConcretizedCallable):\n                arraylike_args.append(symbol_or_numeric(inputs))\n            if isinstance(symbol_or_numeric, (float, int, Tensor)):\n                arraylike_args.append(\n                    self.arraylike_fn(symbol_or_numeric, device=self.device)\n                )\n            elif isinstance(symbol_or_numeric, str):\n                arraylike_args.append(inputs[symbol_or_numeric])\n        return self.engine_call(*arraylike_args)  # type: ignore[misc]\n\n    @classmethod\n    def _get_independent_args(cls, cc: ConcretizedCallable) -&gt; set:\n        out: set = set()\n        if len(cc.abstract_args) == 1 and isinstance(cc.abstract_args[0], str):\n            return set([cc.abstract_args[0]])\n        else:\n            for arg in cc.abstract_args:\n                if isinstance(arg, ConcretizedCallable):\n                    res = cls._get_independent_args(arg)\n                    out = out.union(res)\n                else:\n                    if isinstance(arg, str):\n                        out.add(arg)\n        return out\n\n    @property\n    def independent_args(self) -&gt; list:\n        return list(self._get_independent_args(self))\n\n    def __call__(self, inputs: dict[str, ArrayLike] | None = None) -&gt; ArrayLike:\n        return self.evaluate(inputs)\n\n    def __mul__(\n        self, other: str | int | float | complex | ConcretizedCallable\n    ) -&gt; ConcretizedCallable:\n        return ConcretizedCallable(\"mul\", [self, other])\n\n    def __rmul__(\n        self, other: str | int | float | ConcretizedCallable\n    ) -&gt; ConcretizedCallable:\n        return ConcretizedCallable(\"mul\", [other, self])\n\n    def __add__(\n        self, other: str | int | float | ConcretizedCallable\n    ) -&gt; ConcretizedCallable:\n        return ConcretizedCallable(\"add\", [self, other])\n\n    def __radd__(\n        self, other: str | int | float | ConcretizedCallable\n    ) -&gt; ConcretizedCallable:\n        return ConcretizedCallable(\"add\", [other, self])\n\n    def __sub__(\n        self, other: str | int | float | ConcretizedCallable\n    ) -&gt; ConcretizedCallable:\n        return ConcretizedCallable(\"sub\", [self, other])\n\n    def __rsub__(\n        self, other: str | int | float | ConcretizedCallable\n    ) -&gt; ConcretizedCallable:\n        return ConcretizedCallable(\"sub\", [other, self])\n\n    def __pow__(\n        self, other: str | int | float | ConcretizedCallable\n    ) -&gt; ConcretizedCallable:\n        return ConcretizedCallable(\"pow\", [self, other])\n\n    def __rpow__(\n        self, other: str | int | float | ConcretizedCallable\n    ) -&gt; ConcretizedCallable:\n        return ConcretizedCallable(\"pow\", [other, self])\n\n    def __truediv__(\n        self, other: str | int | float | ConcretizedCallable\n    ) -&gt; ConcretizedCallable:\n        return ConcretizedCallable(\"div\", [self, other])\n\n    def __rtruediv__(\n        self, other: str | int | float | ConcretizedCallable\n    ) -&gt; ConcretizedCallable:\n        return ConcretizedCallable(\"div\", [other, self])\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.call_name}({self.abstract_args})\"\n\n    def __neg__(self) -&gt; ConcretizedCallable:\n        return -1 * self\n\n    @property\n    def device(self) -&gt; str:\n        return self._device\n\n    @property\n    def dtype(self) -&gt; Any:\n        return self._dtype\n\n    def to(self, *args: Any, **kwargs: Any) -&gt; ConcretizedCallable:\n        self._device = kwargs.get(\"device\", None)\n        self._dtype = kwargs.get(\"dtype\", None)\n        return self\n</code></pre>"},{"location":"embed/#embedding","title":"Embedding","text":"<p>A class relating variational and feature parameters used in ConcretizedCallable instances to parameter names used in gates.</p> <p>Parameters:</p> Name Type Description Default <code>vparam_names</code> <code>list[str]</code> <p>A list of variational parameters.</p> <code>[]</code> <code>fparam_names</code> <code>list[str]</code> <p>A list of feature parameters.</p> <code>[]</code> <code>var_to_call</code> <code>dict[str, ConcretizedCallable] | None</code> <p>A dict mapping from &lt;<code>parameter_name</code>: ConcretizedCallable&gt; pairs,.</p> <code>None</code> <code>tparam_name</code> <code>str | None</code> <p>Optional name for a time parameter.</p> <code>None</code> <code>engine_name</code> <code>str</code> <p>The name of the linear algebra engine.</p> <code>'torch'</code> <code>device</code> <code>str</code> <p>The device to use</p> <code>'cpu'</code> <p>Example: <pre><code>from __future__ import annotations\n\nimport numpy as np\nimport pytest\nimport torch\nimport torch.autograd.gradcheck\n\nimport pyqtorch as pyq\nfrom pyqtorch.embed import ConcretizedCallable, Embedding\nname0, fn0 = \"fn0\", ConcretizedCallable(\"sin\", [\"x\"])\nname1, fn1 = \"fn1\", ConcretizedCallable(\"mul\", [\"fn0\", \"y\"])\nname2, fn2 = \"fn2\", ConcretizedCallable(\"mul\", [\"fn1\", 2.0])\nname3, fn3 = \"fn3\", ConcretizedCallable(\"log\", [\"fn2\"])\nembedding = pyq.Embedding(\n    vparam_names=[\"x\"],\n    fparam_names=[\"y\"],\n    var_to_call={name0: fn0, name1: fn1, name2: fn2, name3: fn3},\n)\nrx = pyq.RX(0, param_name=name0)\ncry = pyq.CRY(0, 1, param_name=name1)\nphase = pyq.PHASE(1, param_name=name2)\nry = pyq.RY(1, param_name=name3)\ncnot = pyq.CNOT(1, 2)\nops = [rx, cry, phase, ry, cnot]\nn_qubits = 3\ncirc = pyq.QuantumCircuit(n_qubits, ops)\nobs = pyq.Observable([pyq.Z(0)])\n\nstate = pyq.zero_state(n_qubits)\n\nx = torch.rand(1, requires_grad=True)\ny = torch.rand(1, requires_grad=True)\n\nvalues_ad = {\"x\": x, \"y\": y}\nembedded_params = embedding(values_ad)\nwf = pyq.run(circ, state, embedded_params, embedding)\n</code></pre></p> Source code in <code>pyqtorch/embed.py</code> <pre><code>class Embedding:\n    \"\"\"A class relating variational and feature parameters used in ConcretizedCallable instances to\n    parameter names used in gates.\n\n    Arguments:\n        vparam_names: A list of variational parameters.\n        fparam_names: A list of feature parameters.\n        var_to_call: A dict mapping from &lt;`parameter_name`: ConcretizedCallable&gt; pairs,.\n        tparam_name: Optional name for a time parameter.\n        engine_name: The name of the linear algebra engine.\n        device: The device to use\n\n    Example:\n    ```\n    from __future__ import annotations\n\n    import numpy as np\n    import pytest\n    import torch\n    import torch.autograd.gradcheck\n\n    import pyqtorch as pyq\n    from pyqtorch.embed import ConcretizedCallable, Embedding\n    name0, fn0 = \"fn0\", ConcretizedCallable(\"sin\", [\"x\"])\n    name1, fn1 = \"fn1\", ConcretizedCallable(\"mul\", [\"fn0\", \"y\"])\n    name2, fn2 = \"fn2\", ConcretizedCallable(\"mul\", [\"fn1\", 2.0])\n    name3, fn3 = \"fn3\", ConcretizedCallable(\"log\", [\"fn2\"])\n    embedding = pyq.Embedding(\n        vparam_names=[\"x\"],\n        fparam_names=[\"y\"],\n        var_to_call={name0: fn0, name1: fn1, name2: fn2, name3: fn3},\n    )\n    rx = pyq.RX(0, param_name=name0)\n    cry = pyq.CRY(0, 1, param_name=name1)\n    phase = pyq.PHASE(1, param_name=name2)\n    ry = pyq.RY(1, param_name=name3)\n    cnot = pyq.CNOT(1, 2)\n    ops = [rx, cry, phase, ry, cnot]\n    n_qubits = 3\n    circ = pyq.QuantumCircuit(n_qubits, ops)\n    obs = pyq.Observable([pyq.Z(0)])\n\n    state = pyq.zero_state(n_qubits)\n\n    x = torch.rand(1, requires_grad=True)\n    y = torch.rand(1, requires_grad=True)\n\n    values_ad = {\"x\": x, \"y\": y}\n    embedded_params = embedding(values_ad)\n    wf = pyq.run(circ, state, embedded_params, embedding)\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        vparam_names: list[str] = [],\n        fparam_names: list[str] = [],\n        var_to_call: dict[str, ConcretizedCallable] | None = None,\n        tparam_name: str | None = None,\n        engine_name: str = \"torch\",\n        device: str = \"cpu\",\n    ) -&gt; None:\n        var_to_call = var_to_call or dict()\n        self.vparams = {\n            vp: init_param(engine_name, trainable=True, device=device)\n            for vp in vparam_names\n        }\n        self.fparam_names: list[str] = fparam_names\n        self.tparam_name = tparam_name\n        self.var_to_call: dict[str, ConcretizedCallable] = var_to_call\n        self._dtype: DTypeLike = None\n        self.tracked_vars: list[str] = []\n        self._device = device\n        self._tracked_vars_identified = False\n        self.engine_name = engine_name\n\n    @property\n    def root_param_names(self) -&gt; list[str]:\n        return list(self.vparams.keys()) + self.fparam_names\n\n    def embed_all(\n        self,\n        inputs: dict[str, ArrayLike] | None = None,\n    ) -&gt; dict[str, ArrayLike]:\n        \"\"\"The standard embedding of all intermediate and leaf parameters.\n        Include the root_params, i.e., the vparams and fparams original values\n        to be reused in computations.\n        \"\"\"\n        inputs = inputs or dict()\n        for intermediate_or_leaf_var, engine_callable in self.var_to_call.items():\n            # We mutate the original inputs dict and include intermediates and leaves.\n            if not self._tracked_vars_identified:\n                # we do this only on the first embedding call\n                if self.tparam_name and any(\n                    [\n                        p in [self.tparam_name] + self.tracked_vars\n                        for p in engine_callable.abstract_args\n                    ]  # we check if any parameter in the callables args is time\n                    # or depends on an intermediate variable which itself depends on time\n                ):\n                    self.tracked_vars.append(intermediate_or_leaf_var)\n                    # we remember which parameters depend on time\n            inputs[intermediate_or_leaf_var] = engine_callable(inputs)\n        self._tracked_vars_identified = True\n        return inputs\n\n    def reembed_tparam(\n        self,\n        embedded_params: dict[str, ArrayLike],\n        tparam_value: ArrayLike,\n    ) -&gt; dict[str, ArrayLike]:\n        \"\"\"Receive already embedded params containing intermediate and leaf parameters\n        and recalculate the those which are dependent on `tparam_name` using the new value\n        `tparam_value`.\n        \"\"\"\n        if self.tparam_name is None:\n            raise ValueError(\n                \"`reembed_param` requires a `tparam_name` to be passed\\\n                              when initializing the `Embedding` class\"\n            )\n        embedded_params[self.tparam_name] = tparam_value\n        for time_dependent_param in self.tracked_vars:\n            embedded_params[time_dependent_param] = self.var_to_call[\n                time_dependent_param\n            ](embedded_params)\n        return embedded_params\n\n    def __call__(\n        self, inputs: dict[str, ArrayLike] | None = None\n    ) -&gt; dict[str, ArrayLike]:\n        \"\"\"Functional version of legacy embedding: Return a new dictionary\\\n        with all embedded parameters.\"\"\"\n        return self.embed_all(inputs or dict())\n\n    @property\n    def dtype(self) -&gt; DTypeLike:\n        return self._dtype\n\n    @property\n    def device(self) -&gt; str:\n        return self._device\n\n    def to(self, *args: Any, **kwargs: Any) -&gt; Embedding:\n        if self.engine_name == \"torch\":\n            # we only support this for torch for now\n            self.vparams = {p: t.to(*args, **kwargs) for p, t in self.vparams.items()}\n            self.var_to_call = {\n                p: call.to(*args, **kwargs) for p, call in self.var_to_call.items()\n            }\n            # Dtype and device have to be passes as kwargs\n            self._dtype = kwargs.get(\"dtype\", self._dtype)\n            self._device = kwargs.get(\"device\", self._device)\n        return self\n</code></pre>"},{"location":"embed/#pyqtorch.embed.Embedding.embed_all","title":"<code>embed_all(inputs=None)</code>","text":"<p>The standard embedding of all intermediate and leaf parameters. Include the root_params, i.e., the vparams and fparams original values to be reused in computations.</p> Source code in <code>pyqtorch/embed.py</code> <pre><code>def embed_all(\n    self,\n    inputs: dict[str, ArrayLike] | None = None,\n) -&gt; dict[str, ArrayLike]:\n    \"\"\"The standard embedding of all intermediate and leaf parameters.\n    Include the root_params, i.e., the vparams and fparams original values\n    to be reused in computations.\n    \"\"\"\n    inputs = inputs or dict()\n    for intermediate_or_leaf_var, engine_callable in self.var_to_call.items():\n        # We mutate the original inputs dict and include intermediates and leaves.\n        if not self._tracked_vars_identified:\n            # we do this only on the first embedding call\n            if self.tparam_name and any(\n                [\n                    p in [self.tparam_name] + self.tracked_vars\n                    for p in engine_callable.abstract_args\n                ]  # we check if any parameter in the callables args is time\n                # or depends on an intermediate variable which itself depends on time\n            ):\n                self.tracked_vars.append(intermediate_or_leaf_var)\n                # we remember which parameters depend on time\n        inputs[intermediate_or_leaf_var] = engine_callable(inputs)\n    self._tracked_vars_identified = True\n    return inputs\n</code></pre>"},{"location":"embed/#pyqtorch.embed.Embedding.reembed_tparam","title":"<code>reembed_tparam(embedded_params, tparam_value)</code>","text":"<p>Receive already embedded params containing intermediate and leaf parameters and recalculate the those which are dependent on <code>tparam_name</code> using the new value <code>tparam_value</code>.</p> Source code in <code>pyqtorch/embed.py</code> <pre><code>def reembed_tparam(\n    self,\n    embedded_params: dict[str, ArrayLike],\n    tparam_value: ArrayLike,\n) -&gt; dict[str, ArrayLike]:\n    \"\"\"Receive already embedded params containing intermediate and leaf parameters\n    and recalculate the those which are dependent on `tparam_name` using the new value\n    `tparam_value`.\n    \"\"\"\n    if self.tparam_name is None:\n        raise ValueError(\n            \"`reembed_param` requires a `tparam_name` to be passed\\\n                          when initializing the `Embedding` class\"\n        )\n    embedded_params[self.tparam_name] = tparam_value\n    for time_dependent_param in self.tracked_vars:\n        embedded_params[time_dependent_param] = self.var_to_call[\n            time_dependent_param\n        ](embedded_params)\n    return embedded_params\n</code></pre>"},{"location":"fitting_a_function/","title":"Fitting a nonlinear function","text":"<p>Let's have a look at how the <code>QuantumCircuit</code> can be used to fit a simple nonlienar function.</p> <pre><code>from __future__ import annotations\n\nfrom operator import add\nfrom functools import reduce\nimport torch\nimport pyqtorch as pyq\nfrom pyqtorch.composite import hea\nfrom pyqtorch.utils import DiffMode\nfrom pyqtorch.primitives import Parametric\nimport matplotlib.pyplot as plt\n\nfrom torch.nn.functional import mse_loss\n\n# We can train on GPU if available\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# We can also choose the precision we want to train on\nCOMPLEX_DTYPE = torch.complex64\nREAL_DTYPE = torch.float32\nN_QUBITS = 4\nDEPTH = 2\nLR = .2\nDIFF_MODE = DiffMode.ADJOINT\nN_EPOCHS = 75\n\n# Target function and some training data\nfn = lambda x, degree: .05 * reduce(add, (torch.cos(i*x) + torch.sin(i*x) for i in range(degree)), 0)\nx = torch.linspace(0, 10, 100)\ny = fn(x, 5)\n# Lets define a feature map to encode our 'x' values\nfeature_map = [pyq.RX(i, f'x') for i in range(N_QUBITS)]\n# To fit the function, we define a hardware-efficient ansatz with tunable parameters\nansatz, params = hea(N_QUBITS, DEPTH, 'theta')\n# Lets move all necessary components to the DEVICE\ncirc = pyq.QuantumCircuit(N_QUBITS, feature_map + ansatz).to(device=DEVICE, dtype=COMPLEX_DTYPE)\nobservable = pyq.Observable(pyq.Z(0)).to(device=DEVICE, dtype=COMPLEX_DTYPE)\nparams = params.to(device=DEVICE, dtype=REAL_DTYPE)\nx, y = x.to(device=DEVICE, dtype=REAL_DTYPE), y.to(device=DEVICE, dtype=REAL_DTYPE)\nstate = circ.init_state()\n\ndef exp_fn(params: dict[str, torch.Tensor], inputs: dict[str, torch.Tensor]) -&gt; torch.Tensor:\n    return pyq.expectation(circ, state, {**params,**inputs}, observable, DIFF_MODE)\n\nwith torch.no_grad():\n    y_init = exp_fn(params, {'x': x})\n\n# We need to set 'foreach' False since Adam doesnt support float64 on CUDA devices\noptimizer = torch.optim.Adam(params.values(), lr=LR, foreach=False)\n\nfor _ in range(N_EPOCHS):\n    optimizer.zero_grad()\n    y_pred = exp_fn(params, {'x': x})\n    loss = mse_loss(y, y_pred)\n    loss.backward()\n    optimizer.step()\n\nwith torch.no_grad():\n    y_final = exp_fn(params, {'x': x})\n\nplt.figure()\nplt.plot(x.numpy(), y.numpy(), label=\"truth\")\nplt.plot(x.numpy(), y_init.numpy(), label=\"initial\")\nplt.plot(x.numpy(), y_final.numpy(), \"--\", label=\"final\", linewidth=3)\nplt.legend()\n</code></pre> 2025-06-17T13:12:02.381450 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"noise/","title":"Noisy simulation","text":""},{"location":"noise/#digital-noise","title":"Digital Noise","text":"<p>In the description of closed quantum systems, a pure state vector is used to represent the complete quantum state. Thus, pure quantum states are represented by state vectors $|\\psi \\rangle $.</p> <p>However, this description is not sufficient to study open quantum systems. When the system interacts with its environment, quantum systems can be in a mixed state, where quantum information is no longer entirely contained in a single state vector but is distributed probabilistically.</p> <p>To address these more general cases, we consider a probabilistic combination \\(p_i\\) of possible pure states \\(|\\psi_i \\rangle\\). Thus, the system is described by a density matrix \\(\\rho\\) defined as follows:</p> \\[ \\rho = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i| \\] <p>The transformations of the density operator of an open quantum system interacting with its environment (noise) are represented by the super-operator \\(S: \\rho \\rightarrow S(\\rho)\\), often referred to as a quantum channel. Quantum channels, due to the conservation of the probability distribution, must be CPTP (Completely Positive and Trace Preserving). Any CPTP super-operator can be written in the following form:</p> \\[ S(\\rho) = \\sum_i K_i \\rho K^{\\dagger}_i \\] <p>Where \\(K_i\\) are the Kraus operators, and satisfy the property \\(\\sum_i K_i K^{\\dagger}_i = \\mathbb{I}\\). As noise is the result of system interactions with its environment, it is therefore possible to simulate noisy quantum circuit with noise type gates.</p> <p>Thus, <code>pyqtorch</code> implements a large selection of single qubit noise gates such as:</p> <ul> <li>The bit flip channel defined as: \\(\\textbf{BitFlip}(\\rho) =(1-p) \\rho + p X \\rho X^{\\dagger}\\)</li> <li>The phase flip channel defined as: \\(\\textbf{PhaseFlip}(\\rho) = (1-p) \\rho + p Z \\rho Z^{\\dagger}\\)</li> <li>The depolarizing channel defined as: \\(\\textbf{Depolarizing}(\\rho) = (1-p) \\rho + \\frac{p}{3} (X \\rho X^{\\dagger} + Y \\rho Y^{\\dagger} + Z \\rho Z^{\\dagger})\\)</li> <li>The pauli channel defined as: \\(\\textbf{PauliChannel}(\\rho) = (1-p_x-p_y-p_z) \\rho             + p_x X \\rho X^{\\dagger}             + p_y Y \\rho Y^{\\dagger}             + p_z Z \\rho Z^{\\dagger}\\)</li> <li>The amplitude damping channel defined as: \\(\\textbf{AmplitudeDamping}(\\rho) =  K_0 \\rho K_0^{\\dagger} + K_1 \\rho K_1^{\\dagger}\\)     with:     \\(\\begin{equation*}     K_{0} \\ =\\begin{pmatrix}     1 &amp; 0\\\\     0 &amp; \\sqrt{1-\\ \\gamma }     \\end{pmatrix} ,\\ K_{1} \\ =\\begin{pmatrix}     0 &amp; \\sqrt{\\ \\gamma }\\\\     0 &amp; 0     \\end{pmatrix}     \\end{equation*}\\)</li> <li>The phase damping channel defined as: \\(\\textbf{PhaseDamping}(\\rho) = K_0 \\rho K_0^{\\dagger} + K_1 \\rho K_1^{\\dagger}\\)     with:     \\(\\begin{equation*}     K_{0} \\ =\\begin{pmatrix}     1 &amp; 0\\\\     0 &amp; \\sqrt{1-\\ \\gamma }     \\end{pmatrix}, \\ K_{1} \\ =\\begin{pmatrix}     0 &amp; 0\\\\     0 &amp; \\sqrt{\\ \\gamma }     \\end{pmatrix}     \\end{equation*}\\)</li> <li>The generalize amplitude damping channel is defined as: \\(\\textbf{GeneralizedAmplitudeDamping}(\\rho) = K_0 \\rho K_0^{\\dagger} + K_1 \\rho K_1^{\\dagger} + K_2 \\rho K_2^{\\dagger} + K_3 \\rho K_3^{\\dagger}\\)     with: \\(\\begin{cases} K_{0} \\ =\\sqrt{p} \\ \\begin{pmatrix} 1 &amp; 0\\\\ 0 &amp; \\sqrt{1-\\ \\gamma } \\end{pmatrix} ,\\ K_{1} \\ =\\sqrt{p} \\ \\begin{pmatrix} 0 &amp; 0\\\\ 0 &amp; \\sqrt{\\ \\gamma } \\end{pmatrix} \\\\ K_{2} \\ =\\sqrt{1\\ -p} \\ \\begin{pmatrix} \\sqrt{1-\\ \\gamma } &amp; 0\\\\ 0 &amp; 1 \\end{pmatrix} ,\\ K_{3} \\ =\\sqrt{1-p} \\ \\begin{pmatrix} 0 &amp; 0\\\\ \\sqrt{\\ \\gamma } &amp; 0 \\end{pmatrix} \\end{cases}\\)</li> <li>The two-qubit depolarizing channel: described by mapping an input a density matrix \\(\\rho\\) to the Kraus representation \\(\\sum_i p_i  K_i \\rho K_i^{\\dagger}\\) where the \\(K_i\\) are the 16 possible two-qubit pauli matrices. We implement the case where it is described with a single probability input \\(p\\): \\(\\textbf{TwoQubitDepolarizing}(\\rho) = (1-p) \\rho + \\frac{p}{15} (IX \\rho IX + IY \\rho IY + ... + ZZ \\rho ZZ)\\)</li> <li>The two-qubit dephasing channel: with a Kraus representation: \\(\\textbf{TwoQubitDephasing}(\\rho) = (1-p) \\rho + \\frac{1}{3} (IZ \\rho IZ + ZI \\rho ZI + ZZ \\rho ZZ)\\)</li> </ul> <p>Noise gates are <code>Primitive</code> types, but they also request a <code>probability</code> argument to represent the noise affecting the system. And either a vector or a density matrix can be used as an input, but the output will always be a density matrix.</p> <pre><code>import torch\nfrom pyqtorch.noise import AmplitudeDamping, PhaseFlip\nfrom pyqtorch.utils import random_state\n\ninput_state = random_state(n_qubits=2)\nnoise_prob = 0.3\nAmpD = AmplitudeDamping(0,noise_prob)\noutput_state = AmpD(input_state) #It's a density matrix\npf = PhaseFlip(1,0.7)\noutput_state = pf(output_state)\n</code></pre> <p>Noisy circuit initialization is the same as noiseless ones and the output will always be a density matrix. Let\u2019s show its usage through the simulation of a realistic \\(X\\) gate.</p> <p>We know that an \\(X\\) gate flips the state of the qubit, for instance \\(X|0\\rangle = |1\\rangle\\). In practice, it's common for the target qubit to stay in its original state after applying \\(X\\) due to the interactions between it and its environment. The possibility of failure can be represented by a <code>BitFlip</code> gate, which flips the state again after the application of the \\(X\\) gate, returning it to its original state with a probability <code>1 - gate_fidelity</code>.</p> <pre><code>import matplotlib.pyplot as plt\nimport torch\n\nfrom pyqtorch.circuit import QuantumCircuit\nfrom pyqtorch.noise import BitFlip\nfrom pyqtorch.primitives import X\nfrom pyqtorch.utils import product_state\n\n\ninput_state = product_state('00')\nx = X(0)\ngate_fidelity = 0.9\nbf = BitFlip(0,1.-gate_fidelity)\ncirc = QuantumCircuit(2,[x,bf])\noutput_state = circ(input_state)\noutput_state_diag = output_state.diagonal(dim1=0).real\n\nplt.figure()\ndiag_values = output_state_diag.squeeze().numpy()\nplt.bar(range(len(diag_values)), diag_values, color='blue', alpha=0.7)\ncustom_labels = ['00', '01', '10', '11']\nplt.xticks(range(len(diag_values)), custom_labels)\nplt.title(\"Probability of state occurrence\")\nplt.xlabel('Possible States')\nplt.ylabel('Probability')\n</code></pre> 2025-06-17T13:12:02.467967 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"noise/#analog-noise","title":"Analog Noise","text":"<p>Analog noise is made possible by specifying the <code>noise</code> argument in <code>HamiltonianEvolution</code> either as a list of tensors defining the jump operators to use when using Schr\u00f6dinger or Lindblad equation solvers or a <code>AnalogNoise</code> instance. An <code>AnalogNoise</code> instance can be instantiated by providing a list of tensors, and a <code>qubit_support</code> that should be a subset of the qubit support of  <code>HamiltonianEvolution</code>.</p> <pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\nfrom pyqtorch.noise import Depolarizing, AnalogNoise\nfrom pyqtorch.utils import  SolverType\n\nn_qubits = 2\nqubit_targets = list(range(n_qubits))\n\n# Random hermitian hamiltonian\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nhermitian_matrix = matrix + matrix.T.conj()\n\ntime = torch.tensor([1.0])\ntime_symbol = \"t\"\ndur_val = torch.rand(1)\nnoise_ops = Depolarizing(0, error_probability=0.1).tensor(2)\nnoise_ops = [op.squeeze() for op in noise_ops]\n# also can be specified as AnalogNoise\nnoise_ops = AnalogNoise(noise_ops, qubit_support=(0,1))\nsolver = SolverType.DP5_ME\nn_steps = 5\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_matrix, time_symbol, qubit_targets,\n        duration=dur_val, steps=n_steps,\n        solver=solver, noise=noise_ops)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start, values={time_symbol: time})\n</code></pre>   tensor([[[ 0.0789+0.1845j],          [ 0.0216+0.5226j]],          [[ 0.2567+0.5124j],          [-0.0153+0.5979j]]], dtype=torch.complex128)    <p>There is one predefined <code>AnalogNoise</code> available: Depolarizing noise (<code>AnalogDepolarizing</code>) defined with jump operators: \\(L_{0,1,2} = \\sqrt{\\frac{p}{4}} (X, Y, Z)\\). Note we can combine <code>AnalogNoise</code> with the <code>+</code> operator.</p> <pre><code>from pyqtorch.noise import AnalogDepolarizing\nanalog_noise = AnalogDepolarizing(error_param=0.1, qubit_support=0) + AnalogDepolarizing(error_param=0.1, qubit_support=1)\n# we now have a qubit support acting on qubits 0 and 1\n</code></pre>   (0, 1)"},{"location":"noise/#readout-errors","title":"Readout errors","text":"<p>Another source of noise can be added when performing measurements. This is typically described using confusion matrices of the form:</p> \\[ T(x|x')=\\delta_{xx'} \\] <p>where \\(x\\) represent a bitstring. We provide two ways to define readout errors: - <code>ReadoutNoise</code> : where each bit can be corrupted independently given an error probability or a 1D tensor of errors. - <code>CorrelatedReadoutNoise</code> : where we provide the full confusion matrix for all possible bitstrings.</p> <pre><code>import torch\nimport pyqtorch as pyq\nfrom pyqtorch.noise.readout import ReadoutNoise\n\nrx = pyq.RX(0, param_name=\"theta\")\ny = pyq.Y(0)\ncnot = pyq.CNOT(0, 1)\nops = [rx, y, cnot]\nn_qubits = 2\ncirc = pyq.QuantumCircuit(n_qubits, ops)\nstate = pyq.random_state(n_qubits)\ntheta = torch.rand(1, requires_grad=True)\nobs = pyq.Observable(pyq.Z(0))\n\nnoiseless_expectation = pyq.expectation(circ, state, {\"theta\": theta}, observable=obs)\nreadobj = ReadoutNoise(n_qubits, seed=0)\nnoisycirc = pyq.QuantumCircuit(n_qubits, ops, readobj)\nnoisy_expectation = pyq.expectation(noisycirc, state, {\"theta\": theta}, observable=obs, n_shots=1000)\n</code></pre>   Noiseless expectation: 0.7339597762005494 Noisy expectation: 0.71"},{"location":"pde/","title":"Solving a partial differential equation using DQC","text":"<p><code>pyqtorch</code> can also be used to implement DQC to solve a partial differential equation.</p> <pre><code>from __future__ import annotations\n\nfrom functools import reduce\nfrom itertools import product\nfrom operator import add\nfrom typing import Callable\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import Tensor, exp, linspace, ones_like, optim, rand, sin, tensor\nfrom torch.autograd import grad\nfrom pyqtorch.composite import hea\nfrom pyqtorch import CNOT, RX, RY, QuantumCircuit, Z, expectation, Sequence, Merge, Add, Observable\nfrom pyqtorch.primitives import Parametric\nfrom pyqtorch.utils import DiffMode\n\nDIFF_MODE = DiffMode.AD\nDEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n# We can also choose the precision we want to train on\nCOMPLEX_DTYPE = torch.complex64\nREAL_DTYPE = torch.float32\nLR = .15\nN_QUBITS = 4\nDEPTH = 3\nVARIABLES = (\"x\", \"y\")\nN_VARIABLES = len(VARIABLES)\nX_POS, Y_POS = [i for i in range(N_VARIABLES)]\nBATCH_SIZE = 250\nN_EPOCHS = 750\n\n\nclass DomainSampling(torch.nn.Module):\n    def __init__(\n        self, exp_fn: Callable[[Tensor], Tensor], n_inputs: int, batch_size: int, device: torch.device, dtype: torch.dtype\n    ) -&gt; None:\n        super().__init__()\n        self.exp_fn = exp_fn\n        self.n_inputs = n_inputs\n        self.batch_size = batch_size\n        self.device = device\n        self.dtype = dtype\n\n    def sample(self, requires_grad: bool = False) -&gt; Tensor:\n        return rand((self.batch_size, self.n_inputs), requires_grad=requires_grad, device=self.device, dtype=self.dtype)\n\n    def left_boundary(self) -&gt; Tensor:  # u(0,y)=0\n        sample = self.sample()\n        sample[:, X_POS] = 0.0\n        return self.exp_fn(sample).pow(2).mean()\n\n    def right_boundary(self) -&gt; Tensor:  # u(L,y)=0\n        sample = self.sample()\n        sample[:, X_POS] = 1.0\n        return self.exp_fn(sample).pow(2).mean()\n\n    def top_boundary(self) -&gt; Tensor:  # u(x,H)=0\n        sample = self.sample()\n        sample[:, Y_POS] = 1.0\n        return self.exp_fn(sample).pow(2).mean()\n\n    def bottom_boundary(self) -&gt; Tensor:  # u(x,0)=f(x)\n        sample = self.sample()\n        sample[:, Y_POS] = 0.0\n        return (self.exp_fn(sample) - sin(np.pi * sample[:, 0])).pow(2).mean()\n\n    def interior(self) -&gt; Tensor:  # uxx+uyy=0\n        sample = self.sample(requires_grad=True)\n        f = self.exp_fn(sample)\n        dfdxy = grad(\n            f,\n            sample,\n            ones_like(f),\n            create_graph=True,\n        )[0]\n        dfdxxdyy = grad(\n            dfdxy,\n            sample,\n            ones_like(dfdxy),\n        )[0]\n\n        return (dfdxxdyy[:, X_POS] + dfdxxdyy[:, Y_POS]).pow(2).mean()\n\n\nfeature_map = [RX(i, VARIABLES[X_POS]) for i in range(N_QUBITS // 2)] + [\n    RX(i, VARIABLES[Y_POS]) for i in range(N_QUBITS // 2, N_QUBITS)\n]\nansatz, params = hea(N_QUBITS, DEPTH, \"theta\")\ncirc = QuantumCircuit(N_QUBITS, feature_map + ansatz).to(device=DEVICE, dtype=COMPLEX_DTYPE)\nsumZ_obs = Observable([Z(i) for i in range(N_QUBITS)]).to(device=DEVICE, dtype=COMPLEX_DTYPE)\nparams = params.to(device=DEVICE, dtype=REAL_DTYPE)\nstate = circ.init_state()\n\n\ndef exp_fn(inputs: Tensor) -&gt; Tensor:\n    return expectation(\n        circ,\n        state,\n        {**params, **{VARIABLES[X_POS]: inputs[:, X_POS], VARIABLES[Y_POS]: inputs[:, Y_POS]}},\n        sumZ_obs,\n        DIFF_MODE,\n    )\n\n\nsingle_domain_torch = linspace(0, 1, steps=BATCH_SIZE)\ndomain_torch = tensor(list(product(single_domain_torch, single_domain_torch)))\n\nopt = optim.Adam(params.values(), lr=LR)\nsol = DomainSampling(exp_fn, len(VARIABLES), BATCH_SIZE, DEVICE, REAL_DTYPE)\n\nfor _ in range(N_EPOCHS):\n    opt.zero_grad()\n    loss = (\n        sol.left_boundary()\n        + sol.right_boundary()\n        + sol.top_boundary()\n        + sol.bottom_boundary()\n        + sol.interior()\n    )\n    loss.backward()\n    opt.step()\n\ndqc_sol = exp_fn(domain_torch.to(DEVICE)).reshape(BATCH_SIZE, BATCH_SIZE).detach().cpu().numpy()\nanalytic_sol = (\n    (exp(-np.pi * domain_torch[:, X_POS]) * sin(np.pi * domain_torch[:, Y_POS]))\n    .reshape(BATCH_SIZE, BATCH_SIZE)\n    .T\n).numpy()\n\n\nfig, ax = plt.subplots(1, 2, figsize=(7, 7))\nax[0].imshow(analytic_sol, cmap=\"turbo\")\nax[0].set_xlabel(\"x\")\nax[0].set_ylabel(\"y\")\nax[0].set_title(\"Analytical solution u(x,y)\")\nax[1].imshow(dqc_sol, cmap=\"turbo\")\nax[1].set_xlabel(\"x\")\nax[1].set_ylabel(\"y\")\nax[1].set_title(\"DQC solution\")\n</code></pre> 2025-06-17T13:14:31.280942 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"time_dependent/","title":"Time-dependent simulation","text":""},{"location":"time_dependent/#time-dependent-schrodinger-and-lindblad-master-equation-solving","title":"Time-dependent Schr\u00f6dinger and Lindblad master equation solving","text":"<p>For simulating systems described by time-dependent Hamiltonians <code>pyqtorch</code> has a module implementing Schr\u00f6dinger and Lindblad equation solvers.</p> <pre><code>import torch\nfrom torch import Tensor\nfrom pyqtorch.utils import product_state, operator_kron\nfrom pyqtorch.matrices import XMAT, YMAT, IMAT\nfrom pyqtorch.time_dependent.mesolve import mesolve\nfrom pyqtorch.time_dependent.sesolve import sesolve\nfrom pyqtorch.utils import SolverType\n\nn_qubits = 2\nduration = 1.0  # simulation duration\nn_steps = 1000  # number of solver time steps\n\n# prepare initial state\ninput_state = product_state(\"0\"*n_qubits).reshape((-1, 1))\n\n# prepare time-dependent Hamiltonian function\ndef ham_t(t: float) -&gt; Tensor:\n    t = torch.as_tensor(t)\n    return 10.0 * (\n        2.0 * torch.sin(t) * torch.kron(XMAT, torch.eye(2))\n        + 3.0 * t**2 * torch.kron(torch.eye(2), YMAT)\n    )\n\n# solve Schrodinger equation for the system\nt_points = torch.linspace(0, duration, n_steps)\nfinal_state_se = sesolve(ham_t, input_state, t_points, SolverType.DP5_SE).states[-1]\n\n# define jump operator L\nL = IMAT.clone()\nfor i in range(n_qubits-1):\n    L = torch.kron(L, XMAT)\n\n# prepare initial density matrix with batch dimension as the last\nrho0 = torch.matmul(input_state, input_state.T).unsqueeze(-1)\n\n# solve Lindblad master equation\nfinal_state_me = mesolve(ham_t, rho0, [L], t_points, SolverType.DP5_ME).states[-1]\n</code></pre>"}]}